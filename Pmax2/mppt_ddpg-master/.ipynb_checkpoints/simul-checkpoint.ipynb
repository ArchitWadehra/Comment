{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad78cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./model/model_target.ckpt\n",
      "state_0 =  [0. 0. 0.] (3,)\n",
      "step = 1\n",
      "epoch = 0 step = 1 done = False St(V,P,I) = [  1.      375.47095 375.47095] accion = [[1.]] last r = [[0.00750942]] episode reward = [[0.00750942]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 2\n",
      "epoch = 0 step = 2 done = False St(V,P,I) = [  2.      750.9372  375.46625] accion = [[1.]] last r = [[0.01501874]] episode reward = [[0.02252816]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 3\n",
      "epoch = 0 step = 3 done = False St(V,P,I) = [   3.      1126.3972   375.46002] accion = [[1.]] last r = [[0.02252794]] episode reward = [[0.0450561]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 4\n",
      "epoch = 0 step = 4 done = False St(V,P,I) = [   4.      1501.8486   375.45142] accion = [[1.]] last r = [[0.03003697]] episode reward = [[0.07509308]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 5\n",
      "epoch = 0 step = 5 done = False St(V,P,I) = [   5.      1877.2886   375.43994] accion = [[1.]] last r = [[0.03754577]] episode reward = [[0.11263885]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 6\n",
      "epoch = 0 step = 6 done = False St(V,P,I) = [   6.      2252.7124   375.42383] accion = [[1.]] last r = [[0.04505425]] episode reward = [[0.15769309]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 7\n",
      "epoch = 0 step = 7 done = False St(V,P,I) = [   7.     2628.115   375.4026] accion = [[1.]] last r = [[0.0525623]] episode reward = [[0.21025538]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 8\n",
      "epoch = 0 step = 8 done = False St(V,P,I) = [   8.     3003.4883  375.3733] accion = [[1.]] last r = [[0.06006977]] episode reward = [[0.27032515]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 9\n",
      "epoch = 0 step = 9 done = False St(V,P,I) = [   9.      3378.8225   375.33423] accion = [[1.]] last r = [[0.06757645]] episode reward = [[0.3379016]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 10\n",
      "epoch = 0 step = 10 done = False St(V,P,I) = [  10.      3754.102    375.27954] accion = [[1.]] last r = [[0.07508204]] episode reward = [[0.41298363]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 11\n",
      "epoch = 0 step = 11 done = False St(V,P,I) = [  11.      4129.309    375.20703] accion = [[1.]] last r = [[0.08258618]] episode reward = [[0.49556983]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 12\n",
      "epoch = 0 step = 12 done = False St(V,P,I) = [  12.      4504.419    375.10986] accion = [[1.]] last r = [[0.09008838]] episode reward = [[0.5856582]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 13\n",
      "epoch = 0 step = 13 done = False St(V,P,I) = [  13.      4879.3965   374.97754] accion = [[1.]] last r = [[0.09758793]] episode reward = [[0.68324614]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 14\n",
      "epoch = 0 step = 14 done = False St(V,P,I) = [  14.     5254.1963  374.7998] accion = [[1.]] last r = [[0.10508393]] episode reward = [[0.7883301]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 15\n",
      "epoch = 0 step = 15 done = False St(V,P,I) = [  15.      5628.7573   374.56104] accion = [[1.]] last r = [[0.11257514]] episode reward = [[0.90090525]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 16\n",
      "epoch = 0 step = 16 done = False St(V,P,I) = [  16.     6002.9985  374.2412] accion = [[1.]] last r = [[0.12005997]] episode reward = [[1.0209652]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 17\n",
      "epoch = 0 step = 17 done = False St(V,P,I) = [  17.     6376.8105  373.812 ] accion = [[1.]] last r = [[0.1275362]] episode reward = [[1.1485014]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 18\n",
      "epoch = 0 step = 18 done = False St(V,P,I) = [  18.      6750.05     373.23926] accion = [[1.]] last r = [[0.13500099]] episode reward = [[1.2835023]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 19\n",
      "epoch = 0 step = 19 done = False St(V,P,I) = [  19.      7122.523    372.47314] accion = [[1.]] last r = [[0.14245045]] episode reward = [[1.4259528]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 20\n",
      "epoch = 0 step = 20 done = False St(V,P,I) = [  20.      7493.9746   371.45166] accion = [[1.]] last r = [[0.14987949]] episode reward = [[1.5758322]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 21\n",
      "epoch = 0 step = 21 done = False St(V,P,I) = [  21.      7864.0635   370.08887] accion = [[1.]] last r = [[0.15728126]] episode reward = [[1.7331135]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 22\n",
      "epoch = 0 step = 22 done = False St(V,P,I) = [  22.      8232.34     368.27637] accion = [[1.]] last r = [[0.16464679]] episode reward = [[1.8977603]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 23\n",
      "epoch = 0 step = 23 done = False St(V,P,I) = [  23.     8598.207   365.8672] accion = [[1.]] last r = [[0.17196414]] episode reward = [[2.0697243]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 24\n",
      "epoch = 0 step = 24 done = False St(V,P,I) = [  24.     8960.869   362.6621] accion = [[1.]] last r = [[0.17921738]] episode reward = [[2.2489417]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 25\n",
      "epoch = 0 step = 25 done = False St(V,P,I) = [  25.      9319.285    358.41602] accion = [[1.]] last r = [[0.1863857]] episode reward = [[2.4353273]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 26\n",
      "epoch = 0 step = 26 done = False St(V,P,I) = [  26.      9672.066    352.78125] accion = [[1.]] last r = [[0.19344133]] episode reward = [[2.6287687]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 27\n",
      "epoch = 0 step = 27 done = False St(V,P,I) = [   27.      10017.386     345.31934] accion = [[1.]] last r = [[0.20034772]] episode reward = [[2.8291163]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 28\n",
      "epoch = 0 step = 28 done = False St(V,P,I) = [   28.      10352.825     335.43945] accion = [[1.]] last r = [[0.20705651]] episode reward = [[3.0361729]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 29\n",
      "epoch = 0 step = 29 done = False St(V,P,I) = [   29.      10675.201     322.37598] accion = [[1.]] last r = [[0.21350402]] episode reward = [[3.249677]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 30\n",
      "epoch = 0 step = 30 done = False St(V,P,I) = [   30.     10980.31     305.1084] accion = [[1.]] last r = [[0.21960619]] episode reward = [[3.469283]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 31\n",
      "epoch = 0 step = 31 done = False St(V,P,I) = [   31.      11262.617     282.30762] accion = [[1.]] last r = [[0.22525235]] episode reward = [[3.6945355]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 32\n",
      "epoch = 0 step = 32 done = False St(V,P,I) = [   32.      11514.83      252.21289] accion = [[1.]] last r = [[0.2302966]] episode reward = [[3.924832]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 33\n",
      "epoch = 0 step = 33 done = False St(V,P,I) = [   33.      11727.349     212.51855] accion = [[1.]] last r = [[0.23454697]] episode reward = [[4.159379]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 34\n",
      "epoch = 0 step = 34 done = False St(V,P,I) = [   34.      11887.55      160.20117] accion = [[1.]] last r = [[0.23775099]] episode reward = [[4.39713]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 35\n",
      "epoch = 0 step = 35 done = False St(V,P,I) = [   35.      11978.828      91.27832] accion = [[1.]] last r = [[0.23957656]] episode reward = [[4.6367064]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 36\n",
      "epoch = 0 step = 36 done = False St(V,P,I) = [3.6000000e+01 1.1979363e+04 5.3515625e-01] accion = [[0.9999998]] last r = [[0.23958726]] episode reward = [[4.8762937]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 37\n",
      "epoch = 0 step = 37 done = False St(V,P,I) = [   37.      11860.489    -118.87402] accion = [[1.]] last r = [[0.23720978]] episode reward = [[5.1135035]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 38\n",
      "epoch = 0 step = 38 done = False St(V,P,I) = [   38.      11584.563    -275.92578] accion = [[0.99999917]] last r = [[0.23169127]] episode reward = [[5.345195]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 39\n",
      "epoch = 0 step = 39 done = False St(V,P,I) = [   38.999996 11102.185     -482.3789  ] accion = [[0.99999565]] last r = [[0.2220437]] episode reward = [[5.5672383]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 40\n",
      "epoch = 0 step = 40 done = False St(V,P,I) = [   39.99998 10348.534    -753.6504 ] accion = [[0.999984]] last r = [[0.20697068]] episode reward = [[5.774209]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 41\n",
      "epoch = 0 step = 41 done = False St(V,P,I) = [  40.999947 9847.635    -500.8994  ] accion = [[0.999964]] last r = [[0.1969527]] episode reward = [[5.971162]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 42\n",
      "epoch = 0 step = 42 done = False St(V,P,I) = [   41.999905 10087.483      239.84863 ] accion = [[0.9999596]] last r = [[0.20174967]] episode reward = [[6.1729116]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 43\n",
      "epoch = 0 step = 43 done = False St(V,P,I) = [   42.999855 10327.292      239.8086  ] accion = [[0.999949]] last r = [[0.20654584]] episode reward = [[6.3794575]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 44\n",
      "epoch = 0 step = 44 done = False St(V,P,I) = [   43.999794 10567.059      239.7666  ] accion = [[0.9999401]] last r = [[0.21134117]] episode reward = [[6.590799]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 45\n",
      "epoch = 0 step = 45 done = False St(V,P,I) = [   44.999725 10806.781      239.72266 ] accion = [[0.99993324]] last r = [[0.21613562]] episode reward = [[6.8069344]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 46\n",
      "epoch = 0 step = 46 done = False St(V,P,I) = [   45.999653 11046.456      239.6748  ] accion = [[0.99992913]] last r = [[0.22092912]] episode reward = [[7.0278635]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 47\n",
      "epoch = 0 step = 47 done = False St(V,P,I) = [   46.99958 11286.081     239.625  ] accion = [[0.99992603]] last r = [[0.22572163]] episode reward = [[7.2535853]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 48\n",
      "epoch = 0 step = 48 done = False St(V,P,I) = [   47.999504 11525.651      239.57031 ] accion = [[0.999924]] last r = [[0.23051302]] episode reward = [[7.4840984]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 49\n",
      "epoch = 0 step = 49 done = False St(V,P,I) = [   48.999428 11765.164      239.5127  ] accion = [[0.9999221]] last r = [[0.23530328]] episode reward = [[7.719402]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 50\n",
      "epoch = 0 step = 50 done = False St(V,P,I) = [   49.999348 12004.613      239.44922 ] accion = [[0.9999202]] last r = [[0.24009226]] episode reward = [[7.959494]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 51\n",
      "epoch = 0 step = 51 done = False St(V,P,I) = [   50.999268 12243.995      239.38184 ] accion = [[0.99991816]] last r = [[0.2448799]] episode reward = [[8.204374]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 52\n",
      "epoch = 0 step = 52 done = False St(V,P,I) = [   51.999184 12483.303      239.30762 ] accion = [[0.9999164]] last r = [[0.24966605]] episode reward = [[8.454041]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 53\n",
      "epoch = 0 step = 53 done = False St(V,P,I) = [   52.9991  12722.533     239.23047] accion = [[0.9999145]] last r = [[0.25445068]] episode reward = [[8.708491]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 54\n",
      "epoch = 0 step = 54 done = False St(V,P,I) = [   53.999012 12961.678      239.14453 ] accion = [[0.9999132]] last r = [[0.25923356]] episode reward = [[8.967725]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 55\n",
      "epoch = 0 step = 55 done = False St(V,P,I) = [   54.998924 13200.733      239.05566 ] accion = [[0.9999123]] last r = [[0.26401466]] episode reward = [[9.231739]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 56\n",
      "epoch = 0 step = 56 done = False St(V,P,I) = [   55.998837 13439.688      238.95508 ] accion = [[0.99991095]] last r = [[0.26879376]] episode reward = [[9.500533]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 57\n",
      "epoch = 0 step = 57 done = False St(V,P,I) = [   56.998745 13678.537      238.84863 ] accion = [[0.99990964]] last r = [[0.27357075]] episode reward = [[9.774104]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 58\n",
      "epoch = 0 step = 58 done = False St(V,P,I) = [   57.998653 13917.271      238.73438 ] accion = [[0.9999082]] last r = [[0.27834544]] episode reward = [[10.052449]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 59\n",
      "epoch = 0 step = 59 done = False St(V,P,I) = [   58.99856 14155.885     238.61328] accion = [[0.99990714]] last r = [[0.28311768]] episode reward = [[10.3355665]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 60\n",
      "epoch = 0 step = 60 done = False St(V,P,I) = [   59.998466 14394.362      238.47754 ] accion = [[0.99990594]] last r = [[0.28788725]] episode reward = [[10.623454]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 61\n",
      "epoch = 0 step = 61 done = False St(V,P,I) = [   60.99837 14632.699     238.33691] accion = [[0.99990445]] last r = [[0.29265398]] episode reward = [[10.916108]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 62\n",
      "epoch = 0 step = 62 done = False St(V,P,I) = [   61.998276 14870.881      238.18164 ] accion = [[0.9999027]] last r = [[0.2974176]] episode reward = [[11.213526]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 63\n",
      "epoch = 0 step = 63 done = False St(V,P,I) = [   62.998177 15108.896      238.01562 ] accion = [[0.9999015]] last r = [[0.30217794]] episode reward = [[11.515704]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 64\n",
      "epoch = 0 step = 64 done = False St(V,P,I) = [   63.998077 15346.732      237.83594 ] accion = [[0.99990004]] last r = [[0.30693465]] episode reward = [[11.8226385]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 65\n",
      "epoch = 0 step = 65 done = False St(V,P,I) = [   64.99798 15584.375     237.64258] accion = [[0.9998983]] last r = [[0.3116875]] episode reward = [[12.134326]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 66\n",
      "epoch = 0 step = 66 done = False St(V,P,I) = [   65.99787 15821.808     237.43262] accion = [[0.99989605]] last r = [[0.31643614]] episode reward = [[12.450762]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 67\n",
      "epoch = 0 step = 67 done = False St(V,P,I) = [   66.997765 16059.018      237.20996 ] accion = [[0.99989384]] last r = [[0.32118034]] episode reward = [[12.771942]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 68\n",
      "epoch = 0 step = 68 done = False St(V,P,I) = [   67.99766 16295.983     236.96582] accion = [[0.9998914]] last r = [[0.32591966]] episode reward = [[13.097862]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 69\n",
      "epoch = 0 step = 69 done = False St(V,P,I) = [   68.99754 16532.688     236.7041 ] accion = [[0.9998889]] last r = [[0.33065376]] episode reward = [[13.428516]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 70\n",
      "epoch = 0 step = 70 done = False St(V,P,I) = [   69.99743 16769.111     236.42383] accion = [[0.99988747]] last r = [[0.33538222]] episode reward = [[13.763899]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 71\n",
      "epoch = 0 step = 71 done = False St(V,P,I) = [   70.997314 17005.232      236.1211  ] accion = [[0.9998865]] last r = [[0.34010464]] episode reward = [[14.104004]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 72\n",
      "epoch = 0 step = 72 done = False St(V,P,I) = [   71.9972  17241.025     235.79297] accion = [[0.99988556]] last r = [[0.3448205]] episode reward = [[14.448824]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 73\n",
      "epoch = 0 step = 73 done = False St(V,P,I) = [   72.997086 17476.467      235.4414  ] accion = [[0.99988544]] last r = [[0.34952933]] episode reward = [[14.798353]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 74\n",
      "epoch = 0 step = 74 done = False St(V,P,I) = [   73.99697 17711.527     235.06055] accion = [[0.9998857]] last r = [[0.35423055]] episode reward = [[15.152584]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 75\n",
      "epoch = 0 step = 75 done = False St(V,P,I) = [   74.99686 17946.18      234.65234] accion = [[0.9998861]] last r = [[0.35892358]] episode reward = [[15.511508]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 76\n",
      "epoch = 0 step = 76 done = False St(V,P,I) = [   75.99674 18180.389     234.20898] accion = [[0.9998865]] last r = [[0.36360776]] episode reward = [[15.875115]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 77\n",
      "epoch = 0 step = 77 done = False St(V,P,I) = [   76.99663 18414.123     233.73438] accion = [[0.99988717]] last r = [[0.36828247]] episode reward = [[16.243399]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 78\n",
      "epoch = 0 step = 78 done = False St(V,P,I) = [   77.99651 18647.344     233.2207 ] accion = [[0.99988854]] last r = [[0.3729469]] episode reward = [[16.616346]] epsilon = 0.995\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 79\n",
      "epoch = 0 step = 79 done = False St(V,P,I) = [   78.99641 18880.014     232.66992] accion = [[0.9998902]] last r = [[0.37760028]] episode reward = [[16.993946]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 80\n",
      "epoch = 0 step = 80 done = False St(V,P,I) = [   79.9963  19112.084     232.07031] accion = [[0.9998928]] last r = [[0.38224167]] episode reward = [[17.376188]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 81\n",
      "epoch = 0 step = 81 done = False St(V,P,I) = [   80.99619 19343.512     231.42773] accion = [[0.9998955]] last r = [[0.38687024]] episode reward = [[17.763058]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 82\n",
      "epoch = 0 step = 82 done = False St(V,P,I) = [   81.99609 19574.248     230.73633] accion = [[0.9998989]] last r = [[0.39148498]] episode reward = [[18.154543]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 83\n",
      "epoch = 0 step = 83 done = False St(V,P,I) = [   82.995995 19804.234      229.98633 ] accion = [[0.99990237]] last r = [[0.3960847]] episode reward = [[18.550627]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 84\n",
      "epoch = 0 step = 84 done = False St(V,P,I) = [   83.9959  20033.416     229.18164] accion = [[0.99990565]] last r = [[0.40066832]] episode reward = [[18.951296]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 85\n",
      "epoch = 0 step = 85 done = False St(V,P,I) = [   84.99581 20261.727     228.31055] accion = [[0.9999086]] last r = [[0.40523455]] episode reward = [[19.356531]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 86\n",
      "epoch = 0 step = 86 done = False St(V,P,I) = [   85.99572 20489.1       227.37305] accion = [[0.9999117]] last r = [[0.409782]] episode reward = [[19.766314]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 87\n",
      "epoch = 0 step = 87 done = False St(V,P,I) = [   86.995636 20715.46       226.36133 ] accion = [[0.9999143]] last r = [[0.41430923]] episode reward = [[20.180622]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 88\n",
      "epoch = 0 step = 88 done = False St(V,P,I) = [   87.99555 20940.732     225.27148] accion = [[0.99991745]] last r = [[0.41881466]] episode reward = [[20.599438]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 89\n",
      "epoch = 0 step = 89 done = False St(V,P,I) = [   88.995476 21164.826      224.09375 ] accion = [[0.99992055]] last r = [[0.4232965]] episode reward = [[21.022734]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 90\n",
      "epoch = 0 step = 90 done = False St(V,P,I) = [   89.9954  21387.652     222.82617] accion = [[0.99992347]] last r = [[0.42775306]] episode reward = [[21.450487]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 91\n",
      "epoch = 0 step = 91 done = False St(V,P,I) = [   90.99532 21609.11      221.45703] accion = [[0.99992627]] last r = [[0.4321822]] episode reward = [[21.88267]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 92\n",
      "epoch = 0 step = 92 done = False St(V,P,I) = [   91.995255 21829.09       219.98047 ] accion = [[0.99992925]] last r = [[0.4365818]] episode reward = [[22.319252]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 93\n",
      "epoch = 0 step = 93 done = False St(V,P,I) = [   92.995186 22047.479      218.38867 ] accion = [[0.9999321]] last r = [[0.44094956]] episode reward = [[22.760202]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 94\n",
      "epoch = 0 step = 94 done = False St(V,P,I) = [   93.995125 22264.152      216.67383 ] accion = [[0.9999353]] last r = [[0.44528306]] episode reward = [[23.205486]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 95\n",
      "epoch = 0 step = 95 done = False St(V,P,I) = [   94.99506 22478.973     214.82031] accion = [[0.9999382]] last r = [[0.44957945]] episode reward = [[23.655066]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 96\n",
      "epoch = 0 step = 96 done = False St(V,P,I) = [   95.995   22691.795     212.82227] accion = [[0.99994135]] last r = [[0.4538359]] episode reward = [[24.108902]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 97\n",
      "epoch = 0 step = 97 done = False St(V,P,I) = [   96.99495 22902.465     210.66992] accion = [[0.9999444]] last r = [[0.4580493]] episode reward = [[24.566952]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 98\n",
      "epoch = 0 step = 98 done = False St(V,P,I) = [   97.994896 23110.809      208.34375 ] accion = [[0.99994725]] last r = [[0.46221617]] episode reward = [[25.029167]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 99\n",
      "epoch = 0 step = 99 done = False St(V,P,I) = [   98.99484 23316.648     205.83984] accion = [[0.9999498]] last r = [[0.46633297]] episode reward = [[25.4955]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 100\n",
      "epoch = 0 step = 100 done = True St(V,P,I) = [   99.9948  23519.783     203.13477] accion = [[0.9999527]] last r = [[0.47039565]] episode reward = [[25.965897]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 101\n",
      "epoch = 0 step = 101 done = True St(V,P,I) = [  100.99475 23720.002     200.21875] accion = [[0.9999551]] last r = [[0.47440004]] episode reward = [[26.440296]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 102\n",
      "epoch = 0 step = 102 done = True St(V,P,I) = [  101.994705 23917.074      197.07227 ] accion = [[0.9999576]] last r = [[0.4783415]] episode reward = [[26.918638]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 103\n",
      "epoch = 0 step = 103 done = True St(V,P,I) = [  102.99467 24110.756     193.68164] accion = [[0.9999598]] last r = [[0.4822151]] episode reward = [[27.400854]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 104\n",
      "epoch = 0 step = 104 done = True St(V,P,I) = [  103.99463 24300.775     190.01953] accion = [[0.9999616]] last r = [[0.4860155]] episode reward = [[27.88687]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 105\n",
      "epoch = 0 step = 105 done = True St(V,P,I) = [  104.99459 24486.848     186.07227] accion = [[0.9999633]] last r = [[0.48973694]] episode reward = [[28.376606]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 106\n",
      "epoch = 0 step = 106 done = True St(V,P,I) = [  105.99455 24668.662     181.81445] accion = [[0.99996495]] last r = [[0.49337325]] episode reward = [[28.86998]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 107\n",
      "epoch = 0 step = 107 done = True St(V,P,I) = [  106.99452 24845.88      177.21875] accion = [[0.9999664]] last r = [[0.4969176]] episode reward = [[29.366898]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 108\n",
      "epoch = 0 step = 108 done = True St(V,P,I) = [  107.99449 25018.148     172.26758] accion = [[0.99996734]] last r = [[0.500363]] episode reward = [[29.86726]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 109\n",
      "epoch = 0 step = 109 done = True St(V,P,I) = [  108.99446 25185.064     166.91602] accion = [[0.99996734]] last r = [[0.50370127]] episode reward = [[30.370962]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 110\n",
      "epoch = 0 step = 110 done = True St(V,P,I) = [  109.99443 25346.215     161.15039] accion = [[0.99996704]] last r = [[0.5069243]] episode reward = [[30.877886]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 111\n",
      "epoch = 0 step = 111 done = True St(V,P,I) = [  110.99439 25501.145     154.92969] accion = [[0.9999655]] last r = [[0.5100229]] episode reward = [[31.387909]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 112\n",
      "epoch = 0 step = 112 done = True St(V,P,I) = [  111.994354 25649.363      148.21875 ] accion = [[0.99996233]] last r = [[0.51298726]] episode reward = [[31.900896]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 113\n",
      "epoch = 0 step = 113 done = True St(V,P,I) = [  112.99431 25790.338     140.97461] accion = [[0.9999561]] last r = [[0.51580673]] episode reward = [[32.416702]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 114\n",
      "epoch = 0 step = 114 done = True St(V,P,I) = [  113.994255 25923.502      133.16406 ] accion = [[0.9999445]] last r = [[0.51847005]] episode reward = [[32.935173]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 115\n",
      "epoch = 0 step = 115 done = True St(V,P,I) = [  114.99414 26048.238     124.73633] accion = [[0.99988824]] last r = [[0.52096474]] episode reward = [[33.45614]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 116\n",
      "epoch = 0 step = 116 done = True St(V,P,I) = [  115.993614 26163.834      115.5957  ] accion = [[0.9994755]] last r = [[0.5232767]] episode reward = [[33.979416]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 117\n",
      "epoch = 0 step = 117 done = True St(V,P,I) = [  116.98987  26269.312      105.478516] accion = [[0.99625045]] last r = [[0.5253863]] episode reward = [[34.504803]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 118\n",
      "epoch = 0 step = 118 done = True St(V,P,I) = [  117.9555  26361.537      92.22461] accion = [[0.965629]] last r = [[0.52723074]] episode reward = [[35.032032]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 119\n",
      "epoch = 0 step = 119 done = True St(V,P,I) = [  118.57269  26414.977       53.439453] accion = [[0.61719733]] last r = [[0.5282995]] episode reward = [[35.560333]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 120\n",
      "epoch = 0 step = 120 done = True St(V,P,I) = [ 1.1842749e+02  2.6402803e+04 -1.2173828e+01] accion = [[-0.14520507]] last r = [[0.528056]] episode reward = [[36.08839]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 121\n",
      "epoch = 0 step = 121 done = True St(V,P,I) = [1.1848671e+02 2.6407801e+04 4.9980469e+00] accion = [[0.0592176]] last r = [[0.52815604]] episode reward = [[36.616547]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 122\n",
      "epoch = 0 step = 122 done = True St(V,P,I) = [ 1.18462296e+02  2.64057441e+04 -2.05664062e+00] accion = [[-0.02441137]] last r = [[0.52811486]] episode reward = [[37.14466]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 123\n",
      "epoch = 0 step = 123 done = True St(V,P,I) = [1.1847240e+02 2.6406594e+04 8.4960938e-01] accion = [[0.01010394]] last r = [[0.5281319]] episode reward = [[37.672794]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 124\n",
      "epoch = 0 step = 124 done = True St(V,P,I) = [ 1.18468216e+02  2.64062402e+04 -3.53515625e-01] accion = [[-0.00418141]] last r = [[0.5281248]] episode reward = [[38.20092]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 125\n",
      "epoch = 0 step = 125 done = True St(V,P,I) = [1.1846994e+02 2.6406389e+04 1.4843750e-01] accion = [[0.00172461]] last r = [[0.5281278]] episode reward = [[38.72905]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 126\n",
      "epoch = 0 step = 126 done = True St(V,P,I) = [ 1.1846924e+02  2.6406328e+04 -6.0546875e-02] accion = [[-0.00070231]] last r = [[0.52812654]] episode reward = [[39.257175]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 127\n",
      "epoch = 0 step = 127 done = True St(V,P,I) = [1.1846952e+02 2.6406354e+04 2.5390625e-02] accion = [[0.00028311]] last r = [[0.5281271]] episode reward = [[39.7853]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 128\n",
      "epoch = 0 step = 128 done = True St(V,P,I) = [ 1.1846941e+02  2.6406344e+04 -9.7656250e-03] accion = [[-0.00010936]] last r = [[0.5281269]] episode reward = [[40.313427]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 129\n",
      "epoch = 0 step = 129 done = True St(V,P,I) = [1.1846945e+02 2.6406346e+04 1.9531250e-03] accion = [[3.9085742e-05]] last r = [[0.5281269]] episode reward = [[40.841553]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 130\n",
      "epoch = 0 step = 130 done = True St(V,P,I) = [  118.46944 26406.346       0.     ] accion = [[-1.8164514e-05]] last r = [[0.5281269]] episode reward = [[41.36968]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 131\n",
      "epoch = 0 step = 131 done = True St(V,P,I) = [1.18469444e+02 2.64063477e+04 1.95312500e-03] accion = [[8.419155e-06]] last r = [[0.52812696]] episode reward = [[41.897804]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 132\n",
      "epoch = 0 step = 132 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[42.42593]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 133\n",
      "epoch = 0 step = 133 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[42.954056]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 134\n",
      "epoch = 0 step = 134 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[43.48218]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 135\n",
      "epoch = 0 step = 135 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[44.010307]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 136\n",
      "epoch = 0 step = 136 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[44.538433]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 137\n",
      "epoch = 0 step = 137 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[45.06656]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 138\n",
      "epoch = 0 step = 138 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[45.594685]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 139\n",
      "epoch = 0 step = 139 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[46.12281]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 140\n",
      "epoch = 0 step = 140 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[46.650936]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 141\n",
      "epoch = 0 step = 141 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[47.17906]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 142\n",
      "epoch = 0 step = 142 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[47.707188]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 143\n",
      "epoch = 0 step = 143 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[48.235313]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 144\n",
      "epoch = 0 step = 144 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[48.76344]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 145\n",
      "epoch = 0 step = 145 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[49.291565]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 146\n",
      "epoch = 0 step = 146 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[49.81969]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 147\n",
      "epoch = 0 step = 147 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[50.347816]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 148\n",
      "epoch = 0 step = 148 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[50.875942]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 149\n",
      "epoch = 0 step = 149 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[51.404068]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 150\n",
      "epoch = 0 step = 150 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[51.932194]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 151\n",
      "epoch = 0 step = 151 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[52.46032]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 152\n",
      "epoch = 0 step = 152 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[52.988445]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 153\n",
      "epoch = 0 step = 153 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[53.51657]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 154\n",
      "epoch = 0 step = 154 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[54.044697]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 155\n",
      "epoch = 0 step = 155 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[54.572823]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 156\n",
      "epoch = 0 step = 156 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[55.10095]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 157\n",
      "epoch = 0 step = 157 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[55.629074]] epsilon = 0.995\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 158\n",
      "epoch = 0 step = 158 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[56.1572]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 159\n",
      "epoch = 0 step = 159 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[56.685326]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 160\n",
      "epoch = 0 step = 160 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[57.21345]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 161\n",
      "epoch = 0 step = 161 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[57.741577]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 162\n",
      "epoch = 0 step = 162 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[58.269703]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 163\n",
      "epoch = 0 step = 163 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[58.79783]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 164\n",
      "epoch = 0 step = 164 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[59.325954]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 165\n",
      "epoch = 0 step = 165 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[59.85408]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 166\n",
      "epoch = 0 step = 166 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[60.382206]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 167\n",
      "epoch = 0 step = 167 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[60.91033]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 168\n",
      "epoch = 0 step = 168 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[61.438457]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 169\n",
      "epoch = 0 step = 169 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[61.966583]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 170\n",
      "epoch = 0 step = 170 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[62.49471]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 171\n",
      "epoch = 0 step = 171 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[63.022835]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 172\n",
      "epoch = 0 step = 172 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[63.55096]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 173\n",
      "epoch = 0 step = 173 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[64.07909]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 174\n",
      "epoch = 0 step = 174 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[64.607216]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 175\n",
      "epoch = 0 step = 175 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[65.135345]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 176\n",
      "epoch = 0 step = 176 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[65.663475]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 177\n",
      "epoch = 0 step = 177 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[66.191605]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 178\n",
      "epoch = 0 step = 178 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[66.719734]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 179\n",
      "epoch = 0 step = 179 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[67.24786]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 180\n",
      "epoch = 0 step = 180 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[67.77599]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 181\n",
      "epoch = 0 step = 181 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[68.30412]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 182\n",
      "epoch = 0 step = 182 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[68.83225]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 183\n",
      "epoch = 0 step = 183 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[69.36038]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 184\n",
      "epoch = 0 step = 184 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[69.88851]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 185\n",
      "epoch = 0 step = 185 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[70.41664]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 186\n",
      "epoch = 0 step = 186 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[70.94477]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 187\n",
      "epoch = 0 step = 187 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[71.4729]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 188\n",
      "epoch = 0 step = 188 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[72.00103]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 189\n",
      "epoch = 0 step = 189 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[72.52916]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 190\n",
      "epoch = 0 step = 190 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[73.05729]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 191\n",
      "epoch = 0 step = 191 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[73.58542]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 192\n",
      "epoch = 0 step = 192 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[74.11355]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 193\n",
      "epoch = 0 step = 193 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[74.64168]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 194\n",
      "epoch = 0 step = 194 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[75.16981]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 195\n",
      "epoch = 0 step = 195 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[75.69794]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 196\n",
      "epoch = 0 step = 196 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[76.22607]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 197\n",
      "epoch = 0 step = 197 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[76.754196]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 198\n",
      "epoch = 0 step = 198 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[77.282326]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 199\n",
      "epoch = 0 step = 199 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[77.810455]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 200\n",
      "epoch = 0 step = 200 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[78.338585]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 201\n",
      "epoch = 0 step = 201 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[78.866714]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 202\n",
      "epoch = 0 step = 202 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[79.394844]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 203\n",
      "epoch = 0 step = 203 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[79.92297]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 204\n",
      "epoch = 0 step = 204 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[80.4511]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 205\n",
      "epoch = 0 step = 205 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[80.97923]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 206\n",
      "epoch = 0 step = 206 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[81.50736]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 207\n",
      "epoch = 0 step = 207 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[82.03549]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 208\n",
      "epoch = 0 step = 208 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[82.56362]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 209\n",
      "epoch = 0 step = 209 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[83.09175]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 210\n",
      "epoch = 0 step = 210 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[83.61988]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 211\n",
      "epoch = 0 step = 211 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[84.14801]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 212\n",
      "epoch = 0 step = 212 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[84.67614]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 213\n",
      "epoch = 0 step = 213 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[85.20427]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 214\n",
      "epoch = 0 step = 214 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[85.7324]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 215\n",
      "epoch = 0 step = 215 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[86.26053]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 216\n",
      "epoch = 0 step = 216 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[86.78866]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 217\n",
      "epoch = 0 step = 217 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[87.31679]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 218\n",
      "epoch = 0 step = 218 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[87.84492]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 219\n",
      "epoch = 0 step = 219 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[88.37305]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 220\n",
      "epoch = 0 step = 220 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[88.90118]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 221\n",
      "epoch = 0 step = 221 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[89.429306]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 222\n",
      "epoch = 0 step = 222 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[89.957436]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 223\n",
      "epoch = 0 step = 223 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[90.485565]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 224\n",
      "epoch = 0 step = 224 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[91.013695]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 225\n",
      "epoch = 0 step = 225 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[91.541824]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 226\n",
      "epoch = 0 step = 226 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[92.069954]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 227\n",
      "epoch = 0 step = 227 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[92.59808]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 228\n",
      "epoch = 0 step = 228 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[93.12621]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 229\n",
      "epoch = 0 step = 229 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[93.65434]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 230\n",
      "epoch = 0 step = 230 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[94.18247]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 231\n",
      "epoch = 0 step = 231 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[94.7106]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 232\n",
      "epoch = 0 step = 232 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[95.23873]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 233\n",
      "epoch = 0 step = 233 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[95.76686]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 234\n",
      "epoch = 0 step = 234 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[96.29499]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 235\n",
      "epoch = 0 step = 235 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[96.82312]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 236 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[97.35125]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 237\n",
      "epoch = 0 step = 237 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[97.87938]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 238\n",
      "epoch = 0 step = 238 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[98.40751]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 239\n",
      "epoch = 0 step = 239 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[98.93564]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 240\n",
      "epoch = 0 step = 240 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[99.46377]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 241\n",
      "epoch = 0 step = 241 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[99.9919]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 242\n",
      "epoch = 0 step = 242 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[100.52003]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 243\n",
      "epoch = 0 step = 243 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[101.04816]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 244\n",
      "epoch = 0 step = 244 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[101.57629]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 245\n",
      "epoch = 0 step = 245 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[102.104416]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 246\n",
      "epoch = 0 step = 246 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[102.632545]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 247\n",
      "epoch = 0 step = 247 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[103.160675]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 248\n",
      "epoch = 0 step = 248 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[103.688805]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 249\n",
      "epoch = 0 step = 249 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[104.216934]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 250\n",
      "epoch = 0 step = 250 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[104.74506]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 251\n",
      "epoch = 0 step = 251 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[105.27319]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 252\n",
      "epoch = 0 step = 252 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[105.80132]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 253\n",
      "epoch = 0 step = 253 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[106.32945]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 254\n",
      "epoch = 0 step = 254 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[106.85758]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 255\n",
      "epoch = 0 step = 255 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[107.38571]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 256\n",
      "epoch = 0 step = 256 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[107.91384]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 257\n",
      "epoch = 0 step = 257 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[108.44197]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 258\n",
      "epoch = 0 step = 258 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[108.9701]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 259\n",
      "epoch = 0 step = 259 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[109.49823]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 260\n",
      "epoch = 0 step = 260 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[110.02636]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 261\n",
      "epoch = 0 step = 261 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[110.55449]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 262\n",
      "epoch = 0 step = 262 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[111.08262]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 263\n",
      "epoch = 0 step = 263 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[111.61075]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 264\n",
      "epoch = 0 step = 264 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[112.13888]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 265\n",
      "epoch = 0 step = 265 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[112.66701]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 266\n",
      "epoch = 0 step = 266 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[113.19514]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 267\n",
      "epoch = 0 step = 267 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[113.72327]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 268\n",
      "epoch = 0 step = 268 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[114.251396]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 269\n",
      "epoch = 0 step = 269 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[114.779526]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 270\n",
      "epoch = 0 step = 270 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[115.307655]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 271\n",
      "epoch = 0 step = 271 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[115.835785]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 272\n",
      "epoch = 0 step = 272 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[116.363914]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 273\n",
      "epoch = 0 step = 273 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[116.892044]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 274\n",
      "epoch = 0 step = 274 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[117.42017]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 275\n",
      "epoch = 0 step = 275 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[117.9483]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 276\n",
      "epoch = 0 step = 276 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[118.47643]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 277\n",
      "epoch = 0 step = 277 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[119.00456]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 278\n",
      "epoch = 0 step = 278 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[119.53269]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 279\n",
      "epoch = 0 step = 279 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[120.06082]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 280\n",
      "epoch = 0 step = 280 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[120.58895]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 281\n",
      "epoch = 0 step = 281 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[121.11708]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 282\n",
      "epoch = 0 step = 282 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[121.64521]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 283\n",
      "epoch = 0 step = 283 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[122.17334]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 284\n",
      "epoch = 0 step = 284 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[122.70147]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 285\n",
      "epoch = 0 step = 285 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[123.2296]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 286\n",
      "epoch = 0 step = 286 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[123.75773]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 287\n",
      "epoch = 0 step = 287 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[124.28586]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 288\n",
      "epoch = 0 step = 288 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[124.81399]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 289\n",
      "epoch = 0 step = 289 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[125.34212]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 290\n",
      "epoch = 0 step = 290 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[125.87025]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 291\n",
      "epoch = 0 step = 291 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[126.39838]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 292\n",
      "epoch = 0 step = 292 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[126.926506]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 293\n",
      "epoch = 0 step = 293 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[127.454636]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 294\n",
      "epoch = 0 step = 294 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[127.982765]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 295\n",
      "epoch = 0 step = 295 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[128.5109]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 296\n",
      "epoch = 0 step = 296 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[129.03902]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 297\n",
      "epoch = 0 step = 297 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[129.56714]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 298\n",
      "epoch = 0 step = 298 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[130.09526]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 299\n",
      "epoch = 0 step = 299 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[130.62338]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 300\n",
      "epoch = 0 step = 300 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[131.1515]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 301\n",
      "epoch = 0 step = 301 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[131.67963]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 302\n",
      "epoch = 0 step = 302 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[132.20775]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 303\n",
      "epoch = 0 step = 303 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[132.73587]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 304\n",
      "epoch = 0 step = 304 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[133.26399]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 305\n",
      "epoch = 0 step = 305 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[133.79211]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 306\n",
      "epoch = 0 step = 306 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[134.32024]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 307\n",
      "epoch = 0 step = 307 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[134.84836]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 308\n",
      "epoch = 0 step = 308 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[135.37648]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 309\n",
      "epoch = 0 step = 309 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[135.9046]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 310 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[136.43272]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 311\n",
      "epoch = 0 step = 311 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[136.96085]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 312\n",
      "epoch = 0 step = 312 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[137.48897]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 313\n",
      "epoch = 0 step = 313 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[138.01709]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 314\n",
      "epoch = 0 step = 314 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[138.54521]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 315\n",
      "epoch = 0 step = 315 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[139.07333]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 316\n",
      "epoch = 0 step = 316 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[139.60146]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 317\n",
      "epoch = 0 step = 317 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[140.12958]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 318\n",
      "epoch = 0 step = 318 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[140.6577]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 319\n",
      "epoch = 0 step = 319 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[141.18582]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 320\n",
      "epoch = 0 step = 320 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[141.71394]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 321\n",
      "epoch = 0 step = 321 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[142.24207]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 322\n",
      "epoch = 0 step = 322 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[142.77019]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 323\n",
      "epoch = 0 step = 323 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[143.29831]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 324\n",
      "epoch = 0 step = 324 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[143.82643]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 325\n",
      "epoch = 0 step = 325 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[144.35455]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 326\n",
      "epoch = 0 step = 326 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[144.88268]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 327\n",
      "epoch = 0 step = 327 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[145.4108]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 328\n",
      "epoch = 0 step = 328 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[145.93892]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 329\n",
      "epoch = 0 step = 329 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[146.46704]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 330\n",
      "epoch = 0 step = 330 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[146.99516]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 331\n",
      "epoch = 0 step = 331 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[147.52328]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 332\n",
      "epoch = 0 step = 332 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[148.0514]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 333\n",
      "epoch = 0 step = 333 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[148.57953]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 334\n",
      "epoch = 0 step = 334 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[149.10765]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 335\n",
      "epoch = 0 step = 335 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[149.63577]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 336\n",
      "epoch = 0 step = 336 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[150.1639]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 337\n",
      "epoch = 0 step = 337 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[150.69202]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 338\n",
      "epoch = 0 step = 338 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[151.22014]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 339\n",
      "epoch = 0 step = 339 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[151.74826]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 340\n",
      "epoch = 0 step = 340 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[152.27638]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 341\n",
      "epoch = 0 step = 341 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[152.8045]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 342\n",
      "epoch = 0 step = 342 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[153.33263]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 343\n",
      "epoch = 0 step = 343 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[153.86075]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 344\n",
      "epoch = 0 step = 344 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[154.38887]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 345\n",
      "epoch = 0 step = 345 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[154.91699]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 346\n",
      "epoch = 0 step = 346 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[155.44511]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 347\n",
      "epoch = 0 step = 347 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[155.97324]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 348\n",
      "epoch = 0 step = 348 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[156.50136]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 349\n",
      "epoch = 0 step = 349 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[157.02948]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 350\n",
      "epoch = 0 step = 350 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[157.5576]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 351\n",
      "epoch = 0 step = 351 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[158.08572]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 352\n",
      "epoch = 0 step = 352 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[158.61385]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 353\n",
      "epoch = 0 step = 353 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[159.14197]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 354\n",
      "epoch = 0 step = 354 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[159.67009]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 355\n",
      "epoch = 0 step = 355 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[160.19821]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 356\n",
      "epoch = 0 step = 356 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[160.72633]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 357\n",
      "epoch = 0 step = 357 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[161.25446]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 358\n",
      "epoch = 0 step = 358 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[161.78258]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 359\n",
      "epoch = 0 step = 359 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[162.3107]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 360\n",
      "epoch = 0 step = 360 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[162.83882]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 361\n",
      "epoch = 0 step = 361 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[163.36694]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 362\n",
      "epoch = 0 step = 362 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[163.89507]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 363\n",
      "epoch = 0 step = 363 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[164.42319]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 364\n",
      "epoch = 0 step = 364 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[164.95131]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 365\n",
      "epoch = 0 step = 365 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[165.47943]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 366\n",
      "epoch = 0 step = 366 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[166.00755]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 367\n",
      "epoch = 0 step = 367 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[166.53568]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 368\n",
      "epoch = 0 step = 368 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[167.0638]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 369\n",
      "epoch = 0 step = 369 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[167.59192]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 370\n",
      "epoch = 0 step = 370 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[168.12004]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 371\n",
      "epoch = 0 step = 371 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[168.64816]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 372\n",
      "epoch = 0 step = 372 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[169.17628]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 373\n",
      "epoch = 0 step = 373 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[169.7044]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 374\n",
      "epoch = 0 step = 374 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[170.23253]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 375\n",
      "epoch = 0 step = 375 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[170.76065]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 376\n",
      "epoch = 0 step = 376 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[171.28877]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 377\n",
      "epoch = 0 step = 377 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[171.8169]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 378\n",
      "epoch = 0 step = 378 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[172.34502]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 379\n",
      "epoch = 0 step = 379 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[172.87314]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 380\n",
      "epoch = 0 step = 380 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[173.40126]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 381 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[173.92938]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 382\n",
      "epoch = 0 step = 382 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[174.4575]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 383\n",
      "epoch = 0 step = 383 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[174.98563]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 384\n",
      "epoch = 0 step = 384 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[175.51375]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 385\n",
      "epoch = 0 step = 385 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[176.04187]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 386\n",
      "epoch = 0 step = 386 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[176.56999]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 387\n",
      "epoch = 0 step = 387 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[177.09811]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 388\n",
      "epoch = 0 step = 388 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[177.62624]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 389\n",
      "epoch = 0 step = 389 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[178.15436]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 390\n",
      "epoch = 0 step = 390 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[178.68248]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 391\n",
      "epoch = 0 step = 391 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[179.2106]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 392\n",
      "epoch = 0 step = 392 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[179.73872]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 393\n",
      "epoch = 0 step = 393 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[180.26685]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 394\n",
      "epoch = 0 step = 394 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[180.79497]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 395\n",
      "epoch = 0 step = 395 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[181.32309]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 396\n",
      "epoch = 0 step = 396 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[181.85121]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 397\n",
      "epoch = 0 step = 397 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[182.37933]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 398\n",
      "epoch = 0 step = 398 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[182.90746]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 399\n",
      "epoch = 0 step = 399 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[183.43558]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 400\n",
      "epoch = 0 step = 400 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[183.9637]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 401\n",
      "epoch = 0 step = 401 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[184.49182]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 402\n",
      "epoch = 0 step = 402 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[185.01994]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 403\n",
      "epoch = 0 step = 403 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[185.54807]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 404\n",
      "epoch = 0 step = 404 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[186.07619]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 405\n",
      "epoch = 0 step = 405 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[186.60431]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 406\n",
      "epoch = 0 step = 406 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[187.13243]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 407\n",
      "epoch = 0 step = 407 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[187.66055]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 408\n",
      "epoch = 0 step = 408 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[188.18867]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 409\n",
      "epoch = 0 step = 409 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[188.7168]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 410\n",
      "epoch = 0 step = 410 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[189.24492]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 411\n",
      "epoch = 0 step = 411 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[189.77304]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 412\n",
      "epoch = 0 step = 412 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[190.30116]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 413\n",
      "epoch = 0 step = 413 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[190.82928]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 414\n",
      "epoch = 0 step = 414 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[191.3574]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 415\n",
      "epoch = 0 step = 415 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[191.88553]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 416\n",
      "epoch = 0 step = 416 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[192.41365]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 417\n",
      "epoch = 0 step = 417 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[192.94177]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 418\n",
      "epoch = 0 step = 418 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[193.4699]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 419\n",
      "epoch = 0 step = 419 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[193.99802]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 420\n",
      "epoch = 0 step = 420 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[194.52614]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 421\n",
      "epoch = 0 step = 421 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[195.05426]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 422\n",
      "epoch = 0 step = 422 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[195.58238]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 423\n",
      "epoch = 0 step = 423 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[196.1105]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 424\n",
      "epoch = 0 step = 424 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[196.63863]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 425\n",
      "epoch = 0 step = 425 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[197.16675]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 426\n",
      "epoch = 0 step = 426 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[197.69487]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 427\n",
      "epoch = 0 step = 427 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[198.22299]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 428\n",
      "epoch = 0 step = 428 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[198.75111]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 429\n",
      "epoch = 0 step = 429 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[199.27924]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 430\n",
      "epoch = 0 step = 430 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[199.80736]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 431\n",
      "epoch = 0 step = 431 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[200.33548]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 432\n",
      "epoch = 0 step = 432 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[200.8636]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 433\n",
      "epoch = 0 step = 433 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[201.39172]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 434\n",
      "epoch = 0 step = 434 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[201.91985]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 435\n",
      "epoch = 0 step = 435 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[202.44797]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 436\n",
      "epoch = 0 step = 436 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[202.97609]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 437\n",
      "epoch = 0 step = 437 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[203.50421]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 438\n",
      "epoch = 0 step = 438 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[204.03233]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 439\n",
      "epoch = 0 step = 439 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[204.56046]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 440\n",
      "epoch = 0 step = 440 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[205.08858]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 441\n",
      "epoch = 0 step = 441 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[205.6167]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 442\n",
      "epoch = 0 step = 442 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[206.14482]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 443\n",
      "epoch = 0 step = 443 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[206.67294]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 444\n",
      "epoch = 0 step = 444 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[207.20107]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 445\n",
      "epoch = 0 step = 445 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[207.72919]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 446\n",
      "epoch = 0 step = 446 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[208.25731]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 447\n",
      "epoch = 0 step = 447 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[208.78543]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 448\n",
      "epoch = 0 step = 448 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[209.31355]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 449\n",
      "epoch = 0 step = 449 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[209.84167]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 450\n",
      "epoch = 0 step = 450 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[210.3698]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 451\n",
      "epoch = 0 step = 451 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[210.89792]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 452 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[211.42604]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 453\n",
      "epoch = 0 step = 453 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[211.95416]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 454\n",
      "epoch = 0 step = 454 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[212.48228]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 455\n",
      "epoch = 0 step = 455 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[213.0104]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 456\n",
      "epoch = 0 step = 456 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[213.53853]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 457\n",
      "epoch = 0 step = 457 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[214.06665]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 458\n",
      "epoch = 0 step = 458 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[214.59477]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 459\n",
      "epoch = 0 step = 459 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[215.1229]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 460\n",
      "epoch = 0 step = 460 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[215.65102]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 461\n",
      "epoch = 0 step = 461 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[216.17914]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 462\n",
      "epoch = 0 step = 462 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[216.70726]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 463\n",
      "epoch = 0 step = 463 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[217.23538]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 464\n",
      "epoch = 0 step = 464 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[217.7635]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 465\n",
      "epoch = 0 step = 465 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[218.29163]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 466\n",
      "epoch = 0 step = 466 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[218.81975]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 467\n",
      "epoch = 0 step = 467 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[219.34787]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 468\n",
      "epoch = 0 step = 468 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[219.87599]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 469\n",
      "epoch = 0 step = 469 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[220.40411]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 470\n",
      "epoch = 0 step = 470 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[220.93224]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 471\n",
      "epoch = 0 step = 471 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[221.46036]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 472\n",
      "epoch = 0 step = 472 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[221.98848]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 473\n",
      "epoch = 0 step = 473 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[222.5166]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 474\n",
      "epoch = 0 step = 474 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[223.04472]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 475\n",
      "epoch = 0 step = 475 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[223.57285]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 476\n",
      "epoch = 0 step = 476 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[224.10097]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 477\n",
      "epoch = 0 step = 477 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[224.62909]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 478\n",
      "epoch = 0 step = 478 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[225.15721]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 479\n",
      "epoch = 0 step = 479 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[225.68533]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 480\n",
      "epoch = 0 step = 480 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[226.21346]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 481\n",
      "epoch = 0 step = 481 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[226.74158]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 482\n",
      "epoch = 0 step = 482 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[227.2697]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 483\n",
      "epoch = 0 step = 483 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[227.79782]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 484\n",
      "epoch = 0 step = 484 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[228.32594]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 485\n",
      "epoch = 0 step = 485 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[228.85406]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 486\n",
      "epoch = 0 step = 486 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[229.38219]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 487\n",
      "epoch = 0 step = 487 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[229.91031]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 488\n",
      "epoch = 0 step = 488 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[230.43843]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 489\n",
      "epoch = 0 step = 489 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[230.96655]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 490\n",
      "epoch = 0 step = 490 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[231.49467]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 491\n",
      "epoch = 0 step = 491 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[232.0228]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 492\n",
      "epoch = 0 step = 492 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[232.55092]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 493\n",
      "epoch = 0 step = 493 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[233.07904]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 494\n",
      "epoch = 0 step = 494 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[233.60716]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 495\n",
      "epoch = 0 step = 495 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[234.13528]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 496\n",
      "epoch = 0 step = 496 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[234.6634]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 497\n",
      "epoch = 0 step = 497 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[235.19153]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 498\n",
      "epoch = 0 step = 498 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[235.71965]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 499\n",
      "epoch = 0 step = 499 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[236.24777]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 500\n",
      "epoch = 0 step = 500 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[236.7759]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 501\n",
      "epoch = 0 step = 501 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[237.30402]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 502\n",
      "epoch = 0 step = 502 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[237.83214]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 503\n",
      "epoch = 0 step = 503 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[238.36026]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 504\n",
      "epoch = 0 step = 504 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[238.88838]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 505\n",
      "epoch = 0 step = 505 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[239.4165]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 506\n",
      "epoch = 0 step = 506 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[239.94463]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 507\n",
      "epoch = 0 step = 507 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[240.47275]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 508\n",
      "epoch = 0 step = 508 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[241.00087]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 509\n",
      "epoch = 0 step = 509 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[241.52899]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 510\n",
      "epoch = 0 step = 510 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[242.05711]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 511\n",
      "epoch = 0 step = 511 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[242.58524]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 512\n",
      "epoch = 0 step = 512 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[243.11336]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 513\n",
      "epoch = 0 step = 513 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[243.64148]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 514\n",
      "epoch = 0 step = 514 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[244.1696]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 515\n",
      "epoch = 0 step = 515 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[244.69772]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 516\n",
      "epoch = 0 step = 516 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[245.22585]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 517\n",
      "epoch = 0 step = 517 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[245.75397]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 518\n",
      "epoch = 0 step = 518 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[246.28209]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 519\n",
      "epoch = 0 step = 519 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[246.81021]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 520\n",
      "epoch = 0 step = 520 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[247.33833]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 521\n",
      "epoch = 0 step = 521 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[247.86646]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 522\n",
      "epoch = 0 step = 522 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[248.39458]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 523\n",
      "epoch = 0 step = 523 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[248.9227]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 524\n",
      "epoch = 0 step = 524 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[249.45082]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 525\n",
      "epoch = 0 step = 525 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[249.97894]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 526 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[250.50706]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 527\n",
      "epoch = 0 step = 527 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[251.03519]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 528\n",
      "epoch = 0 step = 528 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[251.56331]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 529\n",
      "epoch = 0 step = 529 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[252.09143]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 530\n",
      "epoch = 0 step = 530 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[252.61955]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 531\n",
      "epoch = 0 step = 531 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[253.14767]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 532\n",
      "epoch = 0 step = 532 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[253.6758]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 533\n",
      "epoch = 0 step = 533 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[254.20392]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 534\n",
      "epoch = 0 step = 534 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[254.73204]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 535\n",
      "epoch = 0 step = 535 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[255.26016]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 536\n",
      "epoch = 0 step = 536 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[255.78828]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 537\n",
      "epoch = 0 step = 537 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[256.3164]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 538\n",
      "epoch = 0 step = 538 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[256.84454]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 539\n",
      "epoch = 0 step = 539 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[257.37268]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 540\n",
      "epoch = 0 step = 540 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[257.90082]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 541\n",
      "epoch = 0 step = 541 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[258.42896]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 542\n",
      "epoch = 0 step = 542 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[258.9571]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 543\n",
      "epoch = 0 step = 543 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[259.48523]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 544\n",
      "epoch = 0 step = 544 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[260.01337]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 545\n",
      "epoch = 0 step = 545 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[260.5415]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 546\n",
      "epoch = 0 step = 546 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[261.06964]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 547\n",
      "epoch = 0 step = 547 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[261.59778]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 548\n",
      "epoch = 0 step = 548 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[262.12592]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 549\n",
      "epoch = 0 step = 549 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[262.65405]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 550\n",
      "epoch = 0 step = 550 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[263.1822]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 551\n",
      "epoch = 0 step = 551 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[263.71033]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 552\n",
      "epoch = 0 step = 552 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[264.23846]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 553\n",
      "epoch = 0 step = 553 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[264.7666]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 554\n",
      "epoch = 0 step = 554 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[265.29474]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 555\n",
      "epoch = 0 step = 555 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[265.82288]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 556\n",
      "epoch = 0 step = 556 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[266.351]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 557\n",
      "epoch = 0 step = 557 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[266.87915]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 558\n",
      "epoch = 0 step = 558 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[267.4073]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 559\n",
      "epoch = 0 step = 559 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[267.93542]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 560\n",
      "epoch = 0 step = 560 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[268.46356]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 561\n",
      "epoch = 0 step = 561 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[268.9917]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 562\n",
      "epoch = 0 step = 562 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[269.51984]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 563\n",
      "epoch = 0 step = 563 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[270.04797]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 564\n",
      "epoch = 0 step = 564 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[270.5761]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 565\n",
      "epoch = 0 step = 565 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[271.10425]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 566\n",
      "epoch = 0 step = 566 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[271.6324]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 567\n",
      "epoch = 0 step = 567 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[272.16052]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 568\n",
      "epoch = 0 step = 568 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[272.68866]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 569\n",
      "epoch = 0 step = 569 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[273.2168]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 570\n",
      "epoch = 0 step = 570 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[273.74493]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 571\n",
      "epoch = 0 step = 571 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[274.27307]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 572\n",
      "epoch = 0 step = 572 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[274.8012]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 573\n",
      "epoch = 0 step = 573 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[275.32935]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 574\n",
      "epoch = 0 step = 574 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[275.85748]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 575\n",
      "epoch = 0 step = 575 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[276.38562]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 576\n",
      "epoch = 0 step = 576 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[276.91376]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 577\n",
      "epoch = 0 step = 577 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[277.4419]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 578\n",
      "epoch = 0 step = 578 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[277.97003]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 579\n",
      "epoch = 0 step = 579 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[278.49817]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 580\n",
      "epoch = 0 step = 580 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[279.0263]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 581\n",
      "epoch = 0 step = 581 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[279.55444]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 582\n",
      "epoch = 0 step = 582 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[280.08258]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 583\n",
      "epoch = 0 step = 583 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[280.61072]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 584\n",
      "epoch = 0 step = 584 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[281.13885]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 585\n",
      "epoch = 0 step = 585 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[281.667]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 586\n",
      "epoch = 0 step = 586 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[282.19513]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 587\n",
      "epoch = 0 step = 587 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[282.72327]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 588\n",
      "epoch = 0 step = 588 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[283.2514]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 589\n",
      "epoch = 0 step = 589 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[283.77954]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 590\n",
      "epoch = 0 step = 590 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[284.30768]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 591\n",
      "epoch = 0 step = 591 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[284.83582]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 592\n",
      "epoch = 0 step = 592 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[285.36395]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 593\n",
      "epoch = 0 step = 593 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[285.8921]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 594\n",
      "epoch = 0 step = 594 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[286.42023]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 595\n",
      "epoch = 0 step = 595 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[286.94836]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 596\n",
      "epoch = 0 step = 596 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[287.4765]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 597\n",
      "epoch = 0 step = 597 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[288.00464]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 598\n",
      "epoch = 0 step = 598 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[288.53278]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 599\n",
      "epoch = 0 step = 599 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[289.0609]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 600\n",
      "epoch = 0 step = 600 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[289.58905]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 601\n",
      "epoch = 0 step = 601 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[290.1172]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 602\n",
      "epoch = 0 step = 602 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[290.64532]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 603\n",
      "epoch = 0 step = 603 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[291.17346]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 604\n",
      "epoch = 0 step = 604 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[291.7016]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 605 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[292.22974]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 606\n",
      "epoch = 0 step = 606 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[292.75787]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 607\n",
      "epoch = 0 step = 607 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[293.286]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 608\n",
      "epoch = 0 step = 608 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[293.81415]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 609\n",
      "epoch = 0 step = 609 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[294.3423]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 610\n",
      "epoch = 0 step = 610 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[294.87042]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 611\n",
      "epoch = 0 step = 611 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[295.39856]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 612\n",
      "epoch = 0 step = 612 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[295.9267]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 613\n",
      "epoch = 0 step = 613 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[296.45483]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 614\n",
      "epoch = 0 step = 614 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[296.98297]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 615\n",
      "epoch = 0 step = 615 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[297.5111]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 616\n",
      "epoch = 0 step = 616 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[298.03925]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 617\n",
      "epoch = 0 step = 617 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[298.56738]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 618\n",
      "epoch = 0 step = 618 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[299.09552]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 619\n",
      "epoch = 0 step = 619 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[299.62366]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 620\n",
      "epoch = 0 step = 620 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[300.1518]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 621\n",
      "epoch = 0 step = 621 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[300.67993]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 622\n",
      "epoch = 0 step = 622 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[301.20807]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 623\n",
      "epoch = 0 step = 623 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[301.7362]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 624\n",
      "epoch = 0 step = 624 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[302.26434]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 625\n",
      "epoch = 0 step = 625 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[302.79248]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 626\n",
      "epoch = 0 step = 626 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[303.32062]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 627\n",
      "epoch = 0 step = 627 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[303.84875]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 628\n",
      "epoch = 0 step = 628 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[304.3769]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 629\n",
      "epoch = 0 step = 629 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[304.90503]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 630\n",
      "epoch = 0 step = 630 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[305.43317]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 631\n",
      "epoch = 0 step = 631 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[305.9613]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 632\n",
      "epoch = 0 step = 632 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[306.48944]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 633\n",
      "epoch = 0 step = 633 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[307.01758]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 634\n",
      "epoch = 0 step = 634 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[307.54572]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 635\n",
      "epoch = 0 step = 635 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[308.07385]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 636\n",
      "epoch = 0 step = 636 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[308.602]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 637\n",
      "epoch = 0 step = 637 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[309.13013]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 638\n",
      "epoch = 0 step = 638 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[309.65826]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 639\n",
      "epoch = 0 step = 639 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[310.1864]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 640\n",
      "epoch = 0 step = 640 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[310.71454]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 641\n",
      "epoch = 0 step = 641 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[311.24268]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 642\n",
      "epoch = 0 step = 642 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[311.7708]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 643\n",
      "epoch = 0 step = 643 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[312.29895]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 644\n",
      "epoch = 0 step = 644 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[312.8271]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 645\n",
      "epoch = 0 step = 645 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[313.35522]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 646\n",
      "epoch = 0 step = 646 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[313.88336]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 647\n",
      "epoch = 0 step = 647 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[314.4115]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 648\n",
      "epoch = 0 step = 648 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[314.93964]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 649\n",
      "epoch = 0 step = 649 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[315.46777]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 650\n",
      "epoch = 0 step = 650 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[315.9959]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 651\n",
      "epoch = 0 step = 651 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[316.52405]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 652\n",
      "epoch = 0 step = 652 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[317.0522]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 653\n",
      "epoch = 0 step = 653 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[317.58032]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 654\n",
      "epoch = 0 step = 654 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[318.10846]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 655\n",
      "epoch = 0 step = 655 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[318.6366]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 656\n",
      "epoch = 0 step = 656 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[319.16473]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 657\n",
      "epoch = 0 step = 657 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[319.69287]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 658\n",
      "epoch = 0 step = 658 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[320.221]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 659\n",
      "epoch = 0 step = 659 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[320.74915]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 660\n",
      "epoch = 0 step = 660 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[321.27728]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 661\n",
      "epoch = 0 step = 661 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[321.80542]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 662\n",
      "epoch = 0 step = 662 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[322.33356]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 663\n",
      "epoch = 0 step = 663 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[322.8617]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 664\n",
      "epoch = 0 step = 664 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[323.38983]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 665\n",
      "epoch = 0 step = 665 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[323.91797]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 666\n",
      "epoch = 0 step = 666 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[324.4461]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 667\n",
      "epoch = 0 step = 667 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[324.97424]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 668\n",
      "epoch = 0 step = 668 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[325.50238]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 669\n",
      "epoch = 0 step = 669 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[326.03052]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 670\n",
      "epoch = 0 step = 670 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[326.55865]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 671\n",
      "epoch = 0 step = 671 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[327.0868]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 672\n",
      "epoch = 0 step = 672 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[327.61493]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 673\n",
      "epoch = 0 step = 673 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[328.14307]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 674\n",
      "epoch = 0 step = 674 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[328.6712]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 675\n",
      "epoch = 0 step = 675 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[329.19934]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 676\n",
      "epoch = 0 step = 676 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[329.72748]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 677\n",
      "epoch = 0 step = 677 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[330.2556]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 678\n",
      "epoch = 0 step = 678 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[330.78375]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 679\n",
      "epoch = 0 step = 679 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[331.3119]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 680\n",
      "epoch = 0 step = 680 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[331.84003]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 681\n",
      "epoch = 0 step = 681 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[332.36816]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 682\n",
      "epoch = 0 step = 682 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[332.8963]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 683\n",
      "epoch = 0 step = 683 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[333.42444]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 684 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[333.95258]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 685\n",
      "epoch = 0 step = 685 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[334.4807]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 686\n",
      "epoch = 0 step = 686 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[335.00885]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 687\n",
      "epoch = 0 step = 687 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[335.537]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 688\n",
      "epoch = 0 step = 688 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[336.06512]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 689\n",
      "epoch = 0 step = 689 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[336.59326]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 690\n",
      "epoch = 0 step = 690 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[337.1214]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 691\n",
      "epoch = 0 step = 691 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[337.64954]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 692\n",
      "epoch = 0 step = 692 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[338.17767]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 693\n",
      "epoch = 0 step = 693 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[338.7058]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 694\n",
      "epoch = 0 step = 694 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[339.23395]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 695\n",
      "epoch = 0 step = 695 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[339.7621]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 696\n",
      "epoch = 0 step = 696 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[340.29022]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 697\n",
      "epoch = 0 step = 697 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[340.81836]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 698\n",
      "epoch = 0 step = 698 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[341.3465]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 699\n",
      "epoch = 0 step = 699 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[341.87463]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 700\n",
      "epoch = 0 step = 700 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[342.40277]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 701\n",
      "epoch = 0 step = 701 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[342.9309]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 702\n",
      "epoch = 0 step = 702 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[343.45905]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 703\n",
      "epoch = 0 step = 703 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[343.98718]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 704\n",
      "epoch = 0 step = 704 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[344.51532]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 705\n",
      "epoch = 0 step = 705 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[345.04346]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 706\n",
      "epoch = 0 step = 706 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[345.5716]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 707\n",
      "epoch = 0 step = 707 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[346.09973]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 708\n",
      "epoch = 0 step = 708 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[346.62787]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 709\n",
      "epoch = 0 step = 709 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[347.156]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 710\n",
      "epoch = 0 step = 710 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[347.68414]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 711\n",
      "epoch = 0 step = 711 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[348.21228]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 712\n",
      "epoch = 0 step = 712 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[348.74042]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 713\n",
      "epoch = 0 step = 713 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[349.26855]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 714\n",
      "epoch = 0 step = 714 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[349.7967]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 715\n",
      "epoch = 0 step = 715 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[350.32483]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 716\n",
      "epoch = 0 step = 716 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[350.85297]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 717\n",
      "epoch = 0 step = 717 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[351.3811]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 718\n",
      "epoch = 0 step = 718 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[351.90924]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 719\n",
      "epoch = 0 step = 719 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[352.43738]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 720\n",
      "epoch = 0 step = 720 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[352.9655]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 721\n",
      "epoch = 0 step = 721 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[353.49365]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 722\n",
      "epoch = 0 step = 722 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[354.0218]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 723\n",
      "epoch = 0 step = 723 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[354.54993]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 724\n",
      "epoch = 0 step = 724 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[355.07806]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 725\n",
      "epoch = 0 step = 725 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[355.6062]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 726\n",
      "epoch = 0 step = 726 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[356.13434]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 727\n",
      "epoch = 0 step = 727 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[356.66248]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 728\n",
      "epoch = 0 step = 728 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[357.1906]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 729\n",
      "epoch = 0 step = 729 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[357.71875]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 730\n",
      "epoch = 0 step = 730 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[358.2469]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 731\n",
      "epoch = 0 step = 731 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[358.77502]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 732\n",
      "epoch = 0 step = 732 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[359.30316]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 733\n",
      "epoch = 0 step = 733 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[359.8313]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 734\n",
      "epoch = 0 step = 734 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[360.35944]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 735\n",
      "epoch = 0 step = 735 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[360.88757]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 736\n",
      "epoch = 0 step = 736 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[361.4157]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 737\n",
      "epoch = 0 step = 737 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[361.94385]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 738\n",
      "epoch = 0 step = 738 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[362.472]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 739\n",
      "epoch = 0 step = 739 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[363.00012]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 740\n",
      "epoch = 0 step = 740 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[363.52826]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 741\n",
      "epoch = 0 step = 741 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[364.0564]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 742\n",
      "epoch = 0 step = 742 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[364.58453]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 743\n",
      "epoch = 0 step = 743 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[365.11267]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 744\n",
      "epoch = 0 step = 744 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[365.6408]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 745\n",
      "epoch = 0 step = 745 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[366.16895]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 746\n",
      "epoch = 0 step = 746 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[366.69708]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 747\n",
      "epoch = 0 step = 747 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[367.22522]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 748\n",
      "epoch = 0 step = 748 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[367.75336]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 749\n",
      "epoch = 0 step = 749 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[368.2815]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 750\n",
      "epoch = 0 step = 750 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[368.80963]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 751\n",
      "epoch = 0 step = 751 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[369.33777]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 752\n",
      "epoch = 0 step = 752 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[369.8659]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 753\n",
      "epoch = 0 step = 753 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[370.39404]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 754\n",
      "epoch = 0 step = 754 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[370.92218]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 755\n",
      "epoch = 0 step = 755 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[371.45032]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 756\n",
      "epoch = 0 step = 756 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[371.97845]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 757\n",
      "epoch = 0 step = 757 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[372.5066]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 758\n",
      "epoch = 0 step = 758 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[373.03473]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 759\n",
      "epoch = 0 step = 759 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[373.56287]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 760\n",
      "epoch = 0 step = 760 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[374.091]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 761\n",
      "epoch = 0 step = 761 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[374.61914]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 762\n",
      "epoch = 0 step = 762 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[375.14728]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 763\n",
      "epoch = 0 step = 763 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[375.6754]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 764\n",
      "epoch = 0 step = 764 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[376.20355]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 765\n",
      "epoch = 0 step = 765 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[376.7317]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 766\n",
      "epoch = 0 step = 766 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[377.25983]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 767\n",
      "epoch = 0 step = 767 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[377.78796]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 768\n",
      "epoch = 0 step = 768 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[378.3161]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 769\n",
      "epoch = 0 step = 769 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[378.84424]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 770\n",
      "epoch = 0 step = 770 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[379.37238]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 771\n",
      "epoch = 0 step = 771 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[379.9005]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 772\n",
      "epoch = 0 step = 772 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[380.42865]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 773\n",
      "epoch = 0 step = 773 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[380.9568]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 774\n",
      "epoch = 0 step = 774 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[381.48492]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 775 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[382.01306]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 776\n",
      "epoch = 0 step = 776 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[382.5412]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 777\n",
      "epoch = 0 step = 777 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[383.06934]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 778\n",
      "epoch = 0 step = 778 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[383.59747]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 779\n",
      "epoch = 0 step = 779 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[384.1256]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 780\n",
      "epoch = 0 step = 780 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[384.65375]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 781\n",
      "epoch = 0 step = 781 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[385.1819]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 782\n",
      "epoch = 0 step = 782 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[385.71002]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 783\n",
      "epoch = 0 step = 783 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[386.23816]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 784\n",
      "epoch = 0 step = 784 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[386.7663]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 785\n",
      "epoch = 0 step = 785 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[387.29443]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 786\n",
      "epoch = 0 step = 786 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[387.82257]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 787\n",
      "epoch = 0 step = 787 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[388.3507]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 788\n",
      "epoch = 0 step = 788 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[388.87885]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 789\n",
      "epoch = 0 step = 789 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[389.40698]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 790\n",
      "epoch = 0 step = 790 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[389.93512]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 791\n",
      "epoch = 0 step = 791 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[390.46326]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 792\n",
      "epoch = 0 step = 792 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[390.9914]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 793\n",
      "epoch = 0 step = 793 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[391.51953]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 794\n",
      "epoch = 0 step = 794 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[392.04767]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 795\n",
      "epoch = 0 step = 795 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[392.5758]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 796\n",
      "epoch = 0 step = 796 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[393.10394]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 797\n",
      "epoch = 0 step = 797 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[393.63208]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 798\n",
      "epoch = 0 step = 798 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[394.16022]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 799\n",
      "epoch = 0 step = 799 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[394.68835]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 800\n",
      "epoch = 0 step = 800 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[395.2165]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 801\n",
      "epoch = 0 step = 801 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[395.74463]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 802\n",
      "epoch = 0 step = 802 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[396.27277]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 803\n",
      "epoch = 0 step = 803 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[396.8009]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 804\n",
      "epoch = 0 step = 804 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[397.32904]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 805\n",
      "epoch = 0 step = 805 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[397.85718]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 806\n",
      "epoch = 0 step = 806 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[398.3853]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 807\n",
      "epoch = 0 step = 807 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[398.91345]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 808\n",
      "epoch = 0 step = 808 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[399.4416]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 809\n",
      "epoch = 0 step = 809 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[399.96973]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 810\n",
      "epoch = 0 step = 810 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[400.49786]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 811\n",
      "epoch = 0 step = 811 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[401.026]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 812\n",
      "epoch = 0 step = 812 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[401.55414]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 813\n",
      "epoch = 0 step = 813 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[402.08228]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 814\n",
      "epoch = 0 step = 814 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[402.6104]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 815\n",
      "epoch = 0 step = 815 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[403.13855]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 816\n",
      "epoch = 0 step = 816 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[403.6667]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 817\n",
      "epoch = 0 step = 817 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[404.19482]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 818\n",
      "epoch = 0 step = 818 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[404.72296]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 819\n",
      "epoch = 0 step = 819 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[405.2511]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 820\n",
      "epoch = 0 step = 820 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[405.77924]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 821\n",
      "epoch = 0 step = 821 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[406.30737]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 822\n",
      "epoch = 0 step = 822 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[406.8355]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 823\n",
      "epoch = 0 step = 823 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[407.36365]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 824\n",
      "epoch = 0 step = 824 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[407.89178]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 825\n",
      "epoch = 0 step = 825 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[408.41992]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 826\n",
      "epoch = 0 step = 826 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[408.94806]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 827\n",
      "epoch = 0 step = 827 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[409.4762]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 828\n",
      "epoch = 0 step = 828 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[410.00433]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 829\n",
      "epoch = 0 step = 829 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[410.53247]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 830\n",
      "epoch = 0 step = 830 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[411.0606]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 831\n",
      "epoch = 0 step = 831 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[411.58875]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 832\n",
      "epoch = 0 step = 832 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[412.11688]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 833\n",
      "epoch = 0 step = 833 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[412.64502]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 834\n",
      "epoch = 0 step = 834 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[413.17316]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 835\n",
      "epoch = 0 step = 835 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[413.7013]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 836\n",
      "epoch = 0 step = 836 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[414.22943]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 837\n",
      "epoch = 0 step = 837 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[414.75757]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 838\n",
      "epoch = 0 step = 838 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[415.2857]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 839\n",
      "epoch = 0 step = 839 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[415.81384]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 840\n",
      "epoch = 0 step = 840 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[416.34198]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 841\n",
      "epoch = 0 step = 841 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[416.87012]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 842\n",
      "epoch = 0 step = 842 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[417.39825]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 843\n",
      "epoch = 0 step = 843 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[417.9264]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 844\n",
      "epoch = 0 step = 844 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[418.45453]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 845\n",
      "epoch = 0 step = 845 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[418.98267]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 846\n",
      "epoch = 0 step = 846 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[419.5108]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 847\n",
      "epoch = 0 step = 847 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[420.03894]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 848\n",
      "epoch = 0 step = 848 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[420.56708]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 849\n",
      "epoch = 0 step = 849 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[421.0952]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 850\n",
      "epoch = 0 step = 850 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[421.62335]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 851\n",
      "epoch = 0 step = 851 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[422.1515]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 852\n",
      "epoch = 0 step = 852 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[422.67963]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 853\n",
      "epoch = 0 step = 853 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[423.20776]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 854\n",
      "epoch = 0 step = 854 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[423.7359]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 855\n",
      "epoch = 0 step = 855 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[424.26404]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 856\n",
      "epoch = 0 step = 856 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[424.79218]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 857\n",
      "epoch = 0 step = 857 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[425.3203]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 858\n",
      "epoch = 0 step = 858 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[425.84845]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 859\n",
      "epoch = 0 step = 859 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[426.3766]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 860\n",
      "epoch = 0 step = 860 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[426.90472]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 861\n",
      "epoch = 0 step = 861 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[427.43286]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 862\n",
      "epoch = 0 step = 862 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[427.961]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 863\n",
      "epoch = 0 step = 863 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[428.48914]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 864\n",
      "epoch = 0 step = 864 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[429.01727]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 865 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[429.5454]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 866\n",
      "epoch = 0 step = 866 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[430.07355]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 867\n",
      "epoch = 0 step = 867 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[430.60168]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 868\n",
      "epoch = 0 step = 868 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[431.12982]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 869\n",
      "epoch = 0 step = 869 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[431.65796]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 870\n",
      "epoch = 0 step = 870 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[432.1861]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 871\n",
      "epoch = 0 step = 871 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[432.71423]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 872\n",
      "epoch = 0 step = 872 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[433.24237]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 873\n",
      "epoch = 0 step = 873 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[433.7705]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 874\n",
      "epoch = 0 step = 874 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[434.29865]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 875\n",
      "epoch = 0 step = 875 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[434.82678]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 876\n",
      "epoch = 0 step = 876 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[435.35492]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 877\n",
      "epoch = 0 step = 877 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[435.88306]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 878\n",
      "epoch = 0 step = 878 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[436.4112]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 879\n",
      "epoch = 0 step = 879 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[436.93933]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 880\n",
      "epoch = 0 step = 880 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[437.46747]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 881\n",
      "epoch = 0 step = 881 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[437.9956]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 882\n",
      "epoch = 0 step = 882 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[438.52374]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 883\n",
      "epoch = 0 step = 883 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[439.05188]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 884\n",
      "epoch = 0 step = 884 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[439.58002]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 885\n",
      "epoch = 0 step = 885 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[440.10815]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 886\n",
      "epoch = 0 step = 886 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[440.6363]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 887\n",
      "epoch = 0 step = 887 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[441.16443]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 888\n",
      "epoch = 0 step = 888 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[441.69257]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 889\n",
      "epoch = 0 step = 889 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[442.2207]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 890\n",
      "epoch = 0 step = 890 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[442.74884]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 891\n",
      "epoch = 0 step = 891 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[443.27698]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 892\n",
      "epoch = 0 step = 892 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[443.8051]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 893\n",
      "epoch = 0 step = 893 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[444.33325]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 894\n",
      "epoch = 0 step = 894 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[444.8614]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 895\n",
      "epoch = 0 step = 895 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[445.38953]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 896\n",
      "epoch = 0 step = 896 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[445.91766]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 897\n",
      "epoch = 0 step = 897 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[446.4458]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 898\n",
      "epoch = 0 step = 898 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[446.97394]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 899\n",
      "epoch = 0 step = 899 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[447.50208]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 900\n",
      "epoch = 0 step = 900 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[448.0302]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 901\n",
      "epoch = 0 step = 901 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[448.55835]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 902\n",
      "epoch = 0 step = 902 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[449.0865]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 903\n",
      "epoch = 0 step = 903 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[449.61462]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 904\n",
      "epoch = 0 step = 904 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[450.14276]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 905\n",
      "epoch = 0 step = 905 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[450.6709]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 906\n",
      "epoch = 0 step = 906 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[451.19904]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 907\n",
      "epoch = 0 step = 907 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[451.72717]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 908\n",
      "epoch = 0 step = 908 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[452.2553]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 909\n",
      "epoch = 0 step = 909 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[452.78345]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 910\n",
      "epoch = 0 step = 910 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[453.31158]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 911\n",
      "epoch = 0 step = 911 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[453.83972]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 912\n",
      "epoch = 0 step = 912 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[454.36786]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 913\n",
      "epoch = 0 step = 913 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[454.896]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 914\n",
      "epoch = 0 step = 914 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[455.42413]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 915\n",
      "epoch = 0 step = 915 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[455.95227]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 916\n",
      "epoch = 0 step = 916 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[456.4804]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 917\n",
      "epoch = 0 step = 917 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[457.00854]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 918\n",
      "epoch = 0 step = 918 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[457.53668]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 919\n",
      "epoch = 0 step = 919 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[458.06482]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 920\n",
      "epoch = 0 step = 920 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[458.59296]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 921\n",
      "epoch = 0 step = 921 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[459.1211]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 922\n",
      "epoch = 0 step = 922 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[459.64923]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 923\n",
      "epoch = 0 step = 923 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[460.17737]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 924\n",
      "epoch = 0 step = 924 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[460.7055]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 925\n",
      "epoch = 0 step = 925 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[461.23364]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 926\n",
      "epoch = 0 step = 926 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[461.76178]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 927\n",
      "epoch = 0 step = 927 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[462.28992]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 928\n",
      "epoch = 0 step = 928 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[462.81805]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 929\n",
      "epoch = 0 step = 929 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[463.3462]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 930\n",
      "epoch = 0 step = 930 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[463.87433]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 931\n",
      "epoch = 0 step = 931 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[464.40247]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 932\n",
      "epoch = 0 step = 932 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[464.9306]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 933\n",
      "epoch = 0 step = 933 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[465.45874]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 934\n",
      "epoch = 0 step = 934 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[465.98688]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 935\n",
      "epoch = 0 step = 935 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[466.515]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 936\n",
      "epoch = 0 step = 936 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[467.04315]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 937\n",
      "epoch = 0 step = 937 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[467.5713]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 938\n",
      "epoch = 0 step = 938 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[468.09943]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 939\n",
      "epoch = 0 step = 939 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[468.62756]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 940\n",
      "epoch = 0 step = 940 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[469.1557]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 941\n",
      "epoch = 0 step = 941 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[469.68384]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 942\n",
      "epoch = 0 step = 942 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[470.21198]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 943\n",
      "epoch = 0 step = 943 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[470.7401]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 944\n",
      "epoch = 0 step = 944 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[471.26825]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 945\n",
      "epoch = 0 step = 945 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[471.7964]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 946\n",
      "epoch = 0 step = 946 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[472.32452]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 step = 947 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[472.85266]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 948\n",
      "epoch = 0 step = 948 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[473.3808]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 949\n",
      "epoch = 0 step = 949 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[473.90894]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 950\n",
      "epoch = 0 step = 950 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[474.43707]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 951\n",
      "epoch = 0 step = 951 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[474.9652]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 952\n",
      "epoch = 0 step = 952 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[475.49335]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 953\n",
      "epoch = 0 step = 953 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[476.02148]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 954\n",
      "epoch = 0 step = 954 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[476.54962]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 955\n",
      "epoch = 0 step = 955 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[477.07776]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 956\n",
      "epoch = 0 step = 956 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[477.6059]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 957\n",
      "epoch = 0 step = 957 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[478.13403]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 958\n",
      "epoch = 0 step = 958 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[478.66217]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 959\n",
      "epoch = 0 step = 959 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[479.1903]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 960\n",
      "epoch = 0 step = 960 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[479.71844]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 961\n",
      "epoch = 0 step = 961 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[480.24658]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 962\n",
      "epoch = 0 step = 962 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[480.77472]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 963\n",
      "epoch = 0 step = 963 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[481.30286]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 964\n",
      "epoch = 0 step = 964 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[481.831]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 965\n",
      "epoch = 0 step = 965 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[482.35913]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 966\n",
      "epoch = 0 step = 966 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[482.88727]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 967\n",
      "epoch = 0 step = 967 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[483.4154]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 968\n",
      "epoch = 0 step = 968 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[483.94354]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 969\n",
      "epoch = 0 step = 969 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[484.47168]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 970\n",
      "epoch = 0 step = 970 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[484.99982]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 971\n",
      "epoch = 0 step = 971 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[485.52795]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 972\n",
      "epoch = 0 step = 972 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[486.0561]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 973\n",
      "epoch = 0 step = 973 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[486.58423]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 974\n",
      "epoch = 0 step = 974 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[487.11237]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 975\n",
      "epoch = 0 step = 975 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[487.6405]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 976\n",
      "epoch = 0 step = 976 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[488.16864]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 977\n",
      "epoch = 0 step = 977 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[488.69678]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 978\n",
      "epoch = 0 step = 978 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[489.2249]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 979\n",
      "epoch = 0 step = 979 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[489.75305]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 980\n",
      "epoch = 0 step = 980 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[490.2812]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 981\n",
      "epoch = 0 step = 981 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[490.80933]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 982\n",
      "epoch = 0 step = 982 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[491.33746]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 983\n",
      "epoch = 0 step = 983 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[491.8656]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 984\n",
      "epoch = 0 step = 984 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[492.39374]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 985\n",
      "epoch = 0 step = 985 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[492.92188]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 986\n",
      "epoch = 0 step = 986 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[493.45]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 987\n",
      "epoch = 0 step = 987 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[493.97815]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 988\n",
      "epoch = 0 step = 988 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[494.5063]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 989\n",
      "epoch = 0 step = 989 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[495.03442]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 990\n",
      "epoch = 0 step = 990 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[495.56256]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 991\n",
      "epoch = 0 step = 991 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[496.0907]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 992\n",
      "epoch = 0 step = 992 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[496.61884]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 993\n",
      "epoch = 0 step = 993 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[497.14697]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 994\n",
      "epoch = 0 step = 994 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[497.6751]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 995\n",
      "epoch = 0 step = 995 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[498.20325]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 996\n",
      "epoch = 0 step = 996 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[498.73138]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 997\n",
      "epoch = 0 step = 997 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[499.25952]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 998\n",
      "epoch = 0 step = 998 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[499.78766]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 999\n",
      "epoch = 0 step = 999 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[500.3158]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "step = 1000\n",
      "epoch = 0 step = 1000 done = True St(V,P,I) = [  118.469444 26406.348        0.      ] accion = [[1.683831e-06]] last r = [[0.52812696]] episode reward = [[500.84393]] epsilon = 0.995\n",
      "--------------------------------------------\n",
      "Pmax = [26414.977]\n",
      "Pfinal = 26406.34765625\n",
      "deltaPoptima = [0.03266907] %\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from ou_noise import OUNoise\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "LAYER_1 = 400\n",
    "LAYER_2 = 300\n",
    "LAYER_3 = 300\n",
    "keep_rate = 0.8\n",
    "LAMBDA = 0.00001 # regularization term\n",
    "GAMMA = 0.99\n",
    "class DDPG(object):\n",
    "\n",
    "\n",
    "    def __init__(self, sess, state_dim, action_dim, max_action, min_action, actor_learning_rate, critic_learning_rate, tau, RANDOM_SEED, device = '/cpu:0'):\n",
    "\n",
    "        self.sess = sess\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        self.s_dim = state_dim\n",
    "        self.a_dim = action_dim\n",
    "        self.actor_learning_rate = actor_learning_rate\n",
    "        self.critic_learning_rate = critic_learning_rate\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "        self.max_action = max_action\n",
    "        self.min_action = min_action\n",
    "        # Placeholders\n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, self.s_dim], name='state')\n",
    "        self.action = tf.placeholder(tf.float32, shape=[None, self.a_dim], name='actions')\n",
    "        scope = 'net'    \n",
    "        self.v, self.a, self.scaled_a, self.saver = self._build_net(scope)\n",
    "        self.a_params = tf.trainable_variables(scope=scope + '/actor')\n",
    "        self.c_params = tf.trainable_variables(scope=scope + '/critic')\n",
    "        #self.a_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')\n",
    "        #self.c_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')\n",
    "        scope = 'target'    \n",
    "        self.v_target, self.a_target, self.scaled_a_target, self.saver_target = self._build_net(scope)\n",
    "        self.a_params_target = tf.trainable_variables(scope=scope + '/actor')\n",
    "        self.c_params_target = tf.trainable_variables(scope=scope + '/critic')\n",
    "        #self.a_params_target = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/actor')\n",
    "        #self.c_params_target = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope + '/critic')\n",
    "\n",
    "        \n",
    "        with tf.variable_scope('learning_rate'): \n",
    "            # global step\n",
    "            self.global_step = tf.Variable(0, trainable=False)\n",
    "            self.actor_decay_learning_rate = tf.train.exponential_decay(self.actor_learning_rate, self.global_step, 100000, 0.96, staircase=True)\n",
    "            self.critic_decay_learning_rate = tf.train.exponential_decay(self.critic_learning_rate, self.global_step, 100000, 0.96, staircase=True)\n",
    "        \n",
    "        with tf.device(self.device):\n",
    "            # Op for periodically updating target network with online network\n",
    "            # weights with regularization\n",
    "            self.generate_param_updater()\n",
    "           \n",
    "            self.predicted_q_value = tf.placeholder(tf.float32, [None, 1])\n",
    "            # Define loss and optimization Op\n",
    "            self.squared = tf.square(tf.subtract(self.predicted_q_value,self.v))\n",
    "            self.l2_loss = tf.losses.get_regularization_loss(scope=\"net/critic\")\n",
    "            self.loss = tf.reduce_mean(self.squared) + self.l2_loss \n",
    "            self.critic_optimize = tf.train.AdamOptimizer(self.critic_decay_learning_rate).minimize(self.loss, global_step=self.global_step) \n",
    "            self.action_grads = tf.gradients(self.v, self.action)[0]\n",
    "            self.actor_gradients = tf.gradients(self.a, self.a_params, -self.action_grads)\n",
    "            self.actor_optimize = tf.train.AdamOptimizer(self.actor_decay_learning_rate).apply_gradients(zip(self.actor_gradients, self.a_params), global_step=self.global_step)\n",
    "            \n",
    "            # inverting gradients\n",
    "            self.inverting_gradients_placeholder = tf.placeholder(tf.float32, shape=[None, self.a_dim], name='inverting_gradients')\n",
    "            self._dq_da = tf.gradients(self.v, self.action)[0] # q, a \n",
    "            self._grad = tf.gradients(self.a, self.a_params, -self.inverting_gradients_placeholder)\n",
    "            self._train_actor = tf.train.AdamOptimizer(self.actor_decay_learning_rate).apply_gradients(zip(self._grad, self.a_params),global_step=self.global_step)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    def _build_net(self,scope):\n",
    "       \n",
    "        with tf.device(self.device):        \n",
    "            with tf.variable_scope(scope + '/critic'):\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                net = tf.layers.dense(self.inputs, LAYER_1, tf.nn.relu, name='critic_L1')\n",
    "                initializer = tf.variance_scaling_initializer()\n",
    "                s_union_weights = tf.Variable(initializer.__call__([LAYER_1, LAYER_2]), name='critic_L2_Ws')\n",
    "                a_union_weights = tf.Variable(initializer.__call__([self.a_dim, LAYER_2]), name='critic_L2_Wa')\n",
    "                union_biases = tf.Variable(tf.zeros([LAYER_2]), name='critic_L2_b')\n",
    "                net = tf.nn.relu(tf.matmul(net, s_union_weights) + tf.matmul(self.action, a_union_weights) + union_biases,name='critic_L2')\n",
    "                w_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "                v = tf.layers.dense(net, self.a_dim, kernel_initializer=w_init, name='critic_output')\n",
    "                '''\n",
    "                regularizer = tf.contrib.layers.l2_regularizer(scale=LAMBDA)\n",
    "                l1 = tf.contrib.layers.fully_connected(self.inputs, LAYER_1, weights_regularizer=regularizer, activation_fn=tf.nn.leaky_relu)\n",
    "                l2_a = tf.contrib.layers.fully_connected(self.action, LAYER_2, weights_regularizer=regularizer, activation_fn=None)\n",
    "                l2_s = tf.contrib.layers.fully_connected(l1, LAYER_2, weights_regularizer=regularizer,activation_fn=None)\n",
    "                l2 = tf.nn.leaky_relu(l2_s + l2_a)\n",
    "                v = tf.contrib.layers.fully_connected(l2, 1, weights_regularizer=regularizer, activation_fn=None)\n",
    "                \n",
    "            with tf.variable_scope(scope + '/actor'):\n",
    "                l1 = tf.contrib.layers.fully_connected(self.inputs, LAYER_1,  activation_fn=tf.nn.leaky_relu) # tf.nn.leaky_relu tf.nn.relu\n",
    "                l2 = tf.contrib.layers.fully_connected(l1, LAYER_2,  activation_fn=tf.nn.leaky_relu)\n",
    "                w_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "                a = tf.contrib.layers.fully_connected(l2, self.a_dim, weights_initializer=w_init, activation_fn=tf.nn.tanh) # (para el ddpg)\n",
    "                #a = tf.contrib.layers.fully_connected(l2, self.a_dim, weights_initializer=w_init, activation_fn=None) # (para el inverted)\n",
    "                scaled_a = a\n",
    "                # scaled_a = tf.clip_by_value(a,self.min_action,self.max_action)#tf.multiply(a, self.action_bound)\n",
    "                       \n",
    "        saver = tf.train.Saver()\n",
    "        return v, a, scaled_a, saver\n",
    "\n",
    "    def train(self, s_batch, a_batch, r_batch, t_batch, s2_batch, MINIBATCH_SIZE):\n",
    "        \n",
    "        \n",
    "        # get q target\n",
    "        target_q = self.critic_predict_target(s2_batch, self.predict_action_target(s2_batch))\n",
    "        # obtain y\n",
    "        y_i = []\n",
    "        for k in range(MINIBATCH_SIZE):\n",
    "            if t_batch[k]:\n",
    "                y_i.append(r_batch[k])\n",
    "            else:\n",
    "                y_i.append(r_batch[k] + GAMMA * target_q[k])\n",
    "        # train critic\n",
    "        LOSS = self.critic_train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)))\n",
    "        # print(L2_LOSS)\n",
    "        a_outs = self.predict_action(s_batch)\n",
    "        self.actor_train(s_batch, a_outs)\n",
    "        \n",
    "        self.update_target_network()\n",
    "\n",
    "        return\n",
    "\n",
    "    def test_gradient(self, s_batch, a_batch, r_batch, t_batch, s2_batch, MINIBATCH_SIZE):\n",
    "        \n",
    "        \n",
    "        # get q target\n",
    "        target_q = self.critic_predict_target(s2_batch, self.predict_action_target(s2_batch))\n",
    "        # obtain y\n",
    "        y_i = []\n",
    "        for k in range(MINIBATCH_SIZE):\n",
    "            if t_batch[k]:\n",
    "                y_i.append(r_batch[k])\n",
    "            else:\n",
    "                y_i.append(r_batch[k] + GAMMA * target_q[k])\n",
    "        \n",
    "        # train critic\n",
    "        LOSS = self.critic_train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)))\n",
    "        # train critic\n",
    "        #ac_tor_grads = self._critic_train(s_batch, a_batch, np.reshape(y_i, (MINIBATCH_SIZE, 1)))\n",
    "        #print('a grads',ac_tor_grads)\n",
    "        actions = self.predict_action(s_batch)\n",
    "        \n",
    "        upper = self.max_action\n",
    "        lower = self.min_action\n",
    "\n",
    "        # get dq/da array, action array\n",
    "        #print(upper, '***************')\n",
    "        dq_das = self.sess.run([self._dq_da], feed_dict={self.inputs: s_batch, self.action:actions})[0]\n",
    "        # inverting gradients, if dq_da >= 0, apply upper method, else lower method\n",
    "        inverting_gradients = []\n",
    "        #'''\n",
    "        # print('1 dq_das, actions',dq_das, actions)\n",
    "        '''\n",
    "        # print('dq_das, actions',dq_das, actions)\n",
    "        for dq_da, action in zip(dq_das, actions):\n",
    "            # print('dq_da, action',dq_da, action)\n",
    "            if dq_da >= 0.0:\n",
    "                inverting_gradients.append(dq_da * (self.max_action - action) / (self.max_action - self.min_action))\n",
    "            else:\n",
    "                inverting_gradients.append(dq_da * (action - self.min_action) / (self.max_action - self.min_action))\n",
    "        inverting_gradients = np.array(inverting_gradients).reshape(-1, 1)\n",
    "        '''\n",
    "\n",
    "        for i in range(MINIBATCH_SIZE):\n",
    "            #print('2', i,dq_das[i])\n",
    "            for j in range(self.a_dim):\n",
    "                if dq_das[i][j] >= 0.0:\n",
    "                    dq_das[i][j] = dq_das[i][j] * (self.max_action - actions[i][j]) / (self.max_action - self.min_action)\n",
    "                else:\n",
    "                    dq_das[i][j] = dq_das[i][j] * (actions[i][j] - self.min_action) / (self.max_action - self.min_action)\n",
    "        \n",
    "        # print(dq_das,inverting_gradients)\n",
    "        # exit()\n",
    "        inverting_gradients = dq_das \n",
    "        \n",
    "        # print('2 dq_das, actions',dq_das, actions)\n",
    "        \n",
    "         \n",
    "        #print('1','inverting_gradients',inverting_gradients)\n",
    "        \n",
    "        # print('2','inverting_gradients',inverting_gradients,dq_das, actions)\n",
    "        # time.sleep(1)\n",
    "        # update actor\n",
    "        self.sess.run(self._train_actor, feed_dict={self.inputs: s_batch, self.inverting_gradients_placeholder: inverting_gradients})\n",
    "        self.update_target_network()\n",
    "        return\n",
    "\n",
    "    \n",
    "    def _critic_train(self, inputs, action, predicted_q_value):\n",
    "        return self.sess.run([self.action_grads], feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.action: action,\n",
    "            self.predicted_q_value: predicted_q_value\n",
    "        })\n",
    "\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.sess.run([self.a_updater,self.c_updater])\n",
    "\n",
    "    def generate_param_updater(self):\n",
    "        self.a_updater = [self.a_params_target[i].assign(tf.multiply(self.a_params[i], self.tau) + tf.multiply(self.a_params_target[i], 1. - self.tau))\n",
    "                for i in range(len(self.a_params))]\n",
    "        self.c_updater = [self.c_params_target[i].assign(tf.multiply(self.c_params[i], self.tau) + tf.multiply(self.c_params_target[i], 1. - self.tau))\n",
    "                for i in range(len(self.c_params))]\n",
    "\n",
    "    def critic_train(self, inputs, action, predicted_q_value):\n",
    "        return self.sess.run([self.loss,self.critic_optimize], feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.action: action,\n",
    "            self.predicted_q_value: predicted_q_value\n",
    "        })\n",
    "\n",
    "\n",
    "    def actor_train(self,inputs, action):\n",
    "        return self.sess.run(self.actor_optimize, feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.action: action\n",
    "        })\n",
    "\n",
    "    def save(self):\n",
    "        self.saver.save(self.sess,\"./model/model.ckpt\")\n",
    "        self.saver_target.save(self.sess,\"./model/model_target.ckpt\")\n",
    "        print(\"Model saved in file: actor_model\")\n",
    "\n",
    "    \n",
    "    def load(self):\n",
    "        self.saver.restore(self.sess,\"./model/model.ckpt\")\n",
    "        self.saver_target.restore(self.sess,\"./model/model_target.ckpt\")\n",
    "        \n",
    "\n",
    "\n",
    "    def critic_predict_target(self, state, action):\n",
    "        return self.sess.run(self.v_target, feed_dict={\n",
    "            self.inputs: state,\n",
    "            self.action: action\n",
    "        })\n",
    "        \n",
    "    def predict_action_target(self, state):\n",
    "        return self.sess.run(self.scaled_a_target, feed_dict={\n",
    "            self.inputs: state\n",
    "        })\n",
    "\n",
    "    def predict_action(self, state):\n",
    "        return self.sess.run(self.scaled_a, feed_dict={\n",
    "            self.inputs: state\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "class graficos(object):\n",
    "\n",
    "\n",
    "    def __init__(self,init_state,Temp_0,Irr_0,accion_0=0.):\n",
    "\n",
    "        v=init_state[0]\n",
    "        self.V = list([v])\n",
    "        p=init_state[1]\n",
    "        self.P = list([p])\n",
    "        #deltav=init_state[2]\n",
    "        #self.deltaV = list([deltav])\n",
    "        self.I = list([0.])\n",
    "        self.Temp = list([Temp_0])\n",
    "        self.Irr = list([Irr_0])\n",
    "        self.acciones = list([accion_0])\n",
    "        \n",
    "    def add(self,v,p,i,T,irr,accion):\n",
    "        #add(self,v,p,dv,i,T,irr,accion):\n",
    "        self.V.append(v)\n",
    "        self.P.append(p)\n",
    "        #self.deltaV.append(dv)\n",
    "        self.I.append(i)\n",
    "        self.Temp.append(T)\n",
    "        self.Irr.append(irr)\n",
    "        self.acciones.append(accion)\n",
    "\n",
    "\n",
    "\n",
    "    def plotear(self):\n",
    "        plt.plot(self.V,self.P)\n",
    "        plt.xlabel('V (v)')\n",
    "        plt.ylabel('P (w)')\n",
    "        plt.title('V-P curve')\n",
    "        plt.savefig('VPcurve' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.V,self.I)\n",
    "        plt.xlabel('V (v)')\n",
    "        plt.ylabel('I (A)')\n",
    "        plt.title('V-I curve')\n",
    "        plt.savefig('VIcurve' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.plot(self.V)\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel('V (volts)')\n",
    "        plt.savefig('Tesion' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.I)\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel('I (amperes)')\n",
    "        plt.savefig('Corriente' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.P)\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel(' Power (Watts)')\n",
    "        #plt.title('Power')\n",
    "        plt.savefig('Potencia' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.acciones,'.')\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel('')\n",
    "        plt.title('Manipulated actions')\n",
    "        plt.ylim(-10,10)\n",
    "        plt.savefig('Acciones' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.Temp)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('(ºC)')\n",
    "        plt.title('Temperature profile')\n",
    "        plt.savefig('Temperatura' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(self.Irr)\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel(r'$(W/m^2)$')\n",
    "        plt.title('Solar irradiance profile')\n",
    "        plt.savefig('Irradiancia' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        t = np.linspace(0,len(self.Temp),len(self.Temp))\n",
    "        fig, ax1 = plt.subplots()\n",
    "\n",
    "        color = 'tab:red'\n",
    "        ax1.set_xlabel('Time (sec)')\n",
    "        ax1.set_ylabel('Temp (ºC)', color=color)\n",
    "        ax1.plot(t, self.Temp, color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        color = 'tab:blue'\n",
    "        ax2.set_ylabel('Irradince '+ r'$(W/m^2)$', color=color)  # we already handled the x-label with ax1\n",
    "        ax2.plot(t, self.Irr, color=color)\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        plt.savefig('Temperatura_Irradiancia' + '.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def normalizing_state(state):\n",
    "    #state = [V,P] being V_min = 0, V_max = 210, P_min = 0, P_max = 25000 we use ((xi-x_min)/(x_max-x_min))-1\n",
    "    V_min = 0\n",
    "    V_max = 210\n",
    "    P_min = 0\n",
    "    P_max = 54000\n",
    "    DeltaP_min = -15000\n",
    "    DeltaP_max = 15000\n",
    "\n",
    "    st = [(2*(state[0]-V_min)/(V_max-V_min))-1, (2*(state[1]-P_min)/(P_max-P_min))-1,(2*(state[1]-DeltaP_min)/(DeltaP_max-DeltaP_min))-1]\n",
    "    return st\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from replay_buffer import ReplayBuffer\n",
    "    import gym\n",
    "    import gym_mppt\n",
    "    ACTOR_LEARNING_RATE = 0.0001\n",
    "    CRITIC_LEARNING_RATE =  0.001\n",
    "    # Soft target update param\n",
    "    TAU = 0.001\n",
    "    DEVICE = '/cpu:0'\n",
    "    # ENV_NAME = 'MountainCarContinuous-v0'\n",
    "    ENV_NAME = 'mppt_shaded-v0'#'Pendulum-v0'\n",
    "    # import gym_foo\n",
    "    # ENV_NAME = 'nessie_end_to_end-v0'\n",
    "    max_action = 5. # 5.\n",
    "    min_action = -5.   #-5.\n",
    "    epochs = 1\n",
    "    epsilon = 1.0\n",
    "    min_epsilon = 0.1\n",
    "    EXPLORE = 200\n",
    "    BUFFER_SIZE = 100000\n",
    "    RANDOM_SEED = 51234\n",
    "    MINIBATCH_SIZE = 64# 32 # 5\n",
    "    with tf.Session() as sess:\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "        env = gym.make(ENV_NAME)\n",
    "        state_dim = np.size(env.reset())#2 #env.observation_space.shape[0]\n",
    "        action_dim = 1 #env.action_space.shape[0]\n",
    "        ddpg = DDPG(sess, state_dim, action_dim, max_action, min_action, ACTOR_LEARNING_RATE, CRITIC_LEARNING_RATE, TAU, RANDOM_SEED,device=DEVICE)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ddpg.load()\n",
    "        replay_buffer = ReplayBuffer(BUFFER_SIZE, RANDOM_SEED)\n",
    "        ruido = OUNoise(action_dim, mu = 0.0)\n",
    "        llegadas =0\n",
    "        init_state = np.zeros(state_dim)\n",
    "        irradiancias = list([1000.]) #list([1000., 1000., 1000.]) #list([1000., 500., 1000., 500., 900., 600., 800., 400., 100.]) #irradiancias = list([1000., 1000., 800., 700.]) #list([100., 200., 300., 400., 500., 600., 700., 800., 900., 1000])\n",
    "        temperaturas = list([25.]) #list([25., 25., 25.]) #list([25.0, 25.00, 27.5,  27.50, 29.0, 29., 23.0, 23.0, 23.]) #temperaturas = list([25.0, 27.5, 25., 22.3]) #list([13.5, 15., 17.5, 20., 22.5, 25., 27.5, 30., 32.5, 35])\n",
    "        sh = list([[2, 10, 10, 10, 7, 10]]) #list([[10, 10, 10, 10, 10, 10],[10, 10, 10, 10, 10, 10],[10, 10, 10, 10, 10, 10]])\n",
    "#         sh = list([[2, 10, 10, 10, 7, 10]])\n",
    "#         sh = list([[8, 10, 6, 10, 5, 10]])\n",
    "#         sh = list([[10, 10, 10, 10, 10, 10]])\n",
    "#         sh = list([[1, 10, 3, 10, 5, 10]])\n",
    "#         sh = list([[5, 10, 10, 10, 4, 10]])\n",
    "#         sh = list([[10, 10, 7, 10, 2, 10]])\n",
    "#         sh = list([[10, 10, 1, 10, 2, 10]])\n",
    "#         sh = list([[3, 10, 8, 10, 5, 10]])\n",
    "#         sh = list([[9, 10, 3, 10, 6, 10]])\n",
    "        \n",
    "#         sims = 10\n",
    "#         irradiancias = list()\n",
    "#         temperaturas = list()\n",
    "#         sh = list()\n",
    "#         for simi in range(sims):\n",
    "#             irradiancias.append([1000.])\n",
    "#             temperaturas.append([25.])\n",
    "            \n",
    "#             a = random.sample([1,2,3,4,5,6,7,8,9,10],1)[0]\n",
    "#             b = random.sample([1,2,3,4,5,6,7,8,9,10],1)[0]\n",
    "#             c = random.sample([1,2,3,4,5,6,7,8,9,10],1)[0]\n",
    "#             shi = [a, 10, b, 10, c, 10]\n",
    "#             sh.append(shi)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        Temp_0 = temperaturas[0]\n",
    "        Irr_0 = irradiancias[0]\n",
    "        SH_0 = sh[0]\n",
    "        #env = gym.make(ENV_NAME)\n",
    "        state = env.setTempIrr(init_state,Temp_0,Irr_0,SH_0)\n",
    "        normalized_state = normalizing_state(state)\n",
    "        grafos = graficos(state, Temp_0, Irr_0)\n",
    "        P_max = []\n",
    "        V_max = []\n",
    "        I_max = []\n",
    "        \n",
    "        for i in range(len(temperaturas)):\n",
    "            \n",
    "            #state = np.zeros(3) #env.reset() #Este definirlo a manopla para la simulacion, porque el reset me cambia random las T y las Irr\n",
    "            #env = gym.make(ENV_NAME)\n",
    "            #state = env.setTempIrr(state,temperaturas[i],irradiancias[i])\n",
    "            print('state_0 = ', state, state.shape)\n",
    "            done = False\n",
    "            epsilon -= (epsilon/EXPLORE)\n",
    "            epsilon = np.maximum(min_epsilon,epsilon)\n",
    "            episode_r = 0.\n",
    "            step = 0\n",
    "            max_steps = 1000\n",
    "            Temp_i = temperaturas[i]\n",
    "            Irr_i = irradiancias[i]\n",
    "            SH_i=sh[i]\n",
    "            env.setTempIrr(state,Temp_i,Irr_i,SH_i)\n",
    "            #grafos = graficos(state, Temp_0, Irr_0)\n",
    "            P_episodio = []\n",
    "            V_episodio = []\n",
    "            I_episodio = []\n",
    "            \n",
    "            while (step< max_steps):\n",
    "                step += 1\n",
    "                print('step =', step)\n",
    "\n",
    "                action = ddpg.predict_action(np.reshape(normalized_state,(1,state_dim)))\n",
    "                #print('la accion es:', action, type(action))\n",
    "                #action1 = action\n",
    "                action = np.clip(action,min_action,max_action)\n",
    "                #action = action + max(epsilon,0)*ruido.noise()\n",
    "                #action = np.clip(action,min_action,max_action)\n",
    "                #Temp = Temp_0 #eventualmente se leen desde los sensores...la tomamos ctte e igual a Temp_0\n",
    "                #Irr = Irr_0 #eventualmente se leen desde los sensores...la tomamos ctte e igual a Irr_0\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                #Para ir guardando datos para el ploteo final: \n",
    "                informacion = info #me quedo con el dict de info\n",
    "                #grafos.add(next_state[0], next_state[1], next_state[2], informacion['Corriente'], informacion['Temperatura'], informacion['Irradiancia'], informacion['Accion'])\n",
    "                grafos.add(next_state[0], next_state[1], informacion['Corriente'], informacion['Temperatura'], informacion['Irradiancia'], informacion['Accion'])\n",
    "                #grafos.add(next_state[0], next_state[1], next_state[2],info[0],info[1],info[2],info[3])\n",
    "\n",
    "                V_episodio.append(next_state[0])\n",
    "                P_episodio.append(next_state[1])\n",
    "                I_episodio.append(informacion['Corriente'])\n",
    "                \n",
    "\n",
    "\n",
    "                # reward = np.clip(reward,-1.,1.)\n",
    "                '''\n",
    "                replay_buffer.add(np.reshape(state, (state_dim,)), np.reshape(action, (action_dim,)), reward,\n",
    "                                      done, np.reshape(next_state, (state_dim,)))\n",
    "                '''\n",
    "                state = next_state\n",
    "                normalized_state = normalizing_state(state)\n",
    "                episode_r = episode_r + reward\n",
    "                '''\n",
    "                if replay_buffer.size() > MINIBATCH_SIZE:\n",
    "                    s_batch, a_batch, r_batch, t_batch, s2_batch = replay_buffer.sample_batch(MINIBATCH_SIZE)\n",
    "                    # train normally\n",
    "                    ddpg.train(s_batch, a_batch, r_batch, t_batch, s2_batch,MINIBATCH_SIZE)\n",
    "                    # train with inverted gradients\n",
    "                    #ddpg.test_gradient(s_batch, a_batch, r_batch, t_batch, s2_batch,MINIBATCH_SIZE)\n",
    "                #print(i, step, 'last r', round(reward,3), 'episode reward',round(episode_r,3), 'epsilon', round(epsilon,3))\n",
    "                #print('epoch =',i,'step =' ,step, 'done =', done,'St(V,P,I) =',state,'last r =', round(reward[0][0],3), 'episode reward =',round(episode_r[0][0],3), 'epsilon =', round(epsilon,3))\n",
    "                '''\n",
    "                if done:\n",
    "                    llegadas +=1\n",
    "                print('epoch =',i,'step =' ,step, 'done =', done,'St(V,P,I) =',state, 'accion =',action,'last r =', reward, 'episode reward =',episode_r, 'epsilon =', round(epsilon,3))\n",
    "                print ('--------------------------------------------')\n",
    "\n",
    "            P_max.append(np.max(P_episodio))\n",
    "            P_max_index = np.argmax(P_episodio)\n",
    "            V_max.append(V_episodio[P_max_index])\n",
    "            I_max.append(I_episodio[P_max_index])\n",
    "            \n",
    "\n",
    "\n",
    "        #grafos.plotear()\n",
    "\n",
    "        np.save('Potencia_DDPG',grafos.P)\n",
    "        np.save('Tension_DDPG',grafos.V)\n",
    "        np.save('Corriente_DDPG',grafos.I)\n",
    "        np.save('Acciones_DDPG',grafos.acciones)\n",
    "\n",
    "\n",
    "        print('Pmax =', P_max)\n",
    "        #print('Vmax =', V_max)\n",
    "        #print('Imax =', I_max)\n",
    "        print('Pfinal =', (P_episodio[-2]+P_episodio[-1])/2)\n",
    "        print('deltaPoptima =', 100-((P_episodio[-2]+P_episodio[-1])/2)/P_max*100,'%')\n",
    "\n",
    "\n",
    "\n",
    "        #print('FINNNNNN!!! =) y llego ',llegadas, 'veces!!')                \n",
    "\n",
    "\n",
    "        #ddpg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbf3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fc9352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGnBJREFUeJzt3X2UZFV97vHvIyOoUXBgAHl1UAcBXYKkRXxBEQkiy4TEpbkao6Mhkii+wNVESHJFY7wXvUaNidEQRPANg2KUqBEIMXgxARkiL8OLzCgqI6MzCCKIIuDv/nF2Q9F0z3TP6e7q7vl+1qpVdXbt2rV3n5l6eu9z6nSqCkmS+njQsDsgSZr/DBNJUm+GiSSpN8NEktSbYSJJ6s0wkST1ZphoXkmyNEklWTRN7b0sybnT0dYG3uPgJGsGtq9KcvBMvucwJdkxydeS3Jbkr5P8WZJT2nPTuv80d7hDNRRJngm8G3gCcA9wDXBsVV0ym/2oqk8Cn5zl93zCbL7fEBwN3ARsXX6RbbPhzESzLsnWwBeBvwW2BXYB3g7cOcPvO6Vfnsarv7n/Rj3J8T8auNog2bwYJhqGPQGq6oyquqeqfl5V51bVFQBJHpTkL5J8L8m6JB9Lss14DSV5VZJr2pLKd5L80cBzBydZk+QtSX4IfHSc178yyYUD25XkmCSrgFUbKPubJDck+WmSS5McNNDGQ5OcluSWJFcDTxnznt9Ncmh7fECS/0rykyRrk/xdki3H9OePk6xq7X0wSQaef/XA+K9Osn8r3znJWUnWJ7k+yRsm2hmtrx9Ocl5r54Ikj97Iz+TpSS5Jcmu7f/poW8By4E+T3J7k0CRvS/KJCd57myQfaWP/QZK/SrLFRH3V3GWYaBiuA+5JcnqS5ydZPOb5V7bbc4DHAA8H/m6CttYBLwC2Bl4FvG/0A7V5FN3s59F0yy+T8dvAU4F9NlB2CbBfa/tTwGeSPKQ9dyLw2HZ7Ht2H60TuAY4DlgBPA54LvHZMnRfQBdK+wO+2NknyYuBtwCvoxv9bwI+TPAj4F+Byulnfc4FjkzxvA/14GfCO1o/LeODS373jT7It8CXgA8B2wHuBLyXZrqpe2V777qp6eFX92wbeE+B04G7gccCTgcOAP9zIazQXVZU3b7N+A/YGTgPW0H2YnA3s2J47H3jtQN3HA3fRHeNbChSwaIJ2Pw+8sT0+GPgl8JAN9OOVwIUD2wUcMqbOA8rGaecWYN/2+DvA4QPPHQ2sGdj+LnDoBO0cC/zzmPd+5sD2mcDx7fE5o2Md08ZTge+PKTsB+OgE73ka8OmB7YfThdxu440feDnwjTFt/BfwyoH2/mrgubcBn2iP791/wI50S5sPHaj7UuCrw/736W3qt816/VfDU1XX0H2Qk2Qv4BPA++k+THYGvjdQ/Xvc9+FzP0meTzcT2JNupv0w4MqBKuur6hdT7N4NGytL8ia636B3pvtw3Jrut3pa2WD9wbGM7f+edL/Zj7S+LwIuHVPthwOP76D7sAfYDfj2OM0+Gtg5yU8GyrYA/t9E/Rjsb1XdnuTmMeMYHM/Y/UPb3mUD7Y/n0cCDgbUDK3cPYvyfv+Y4l7k0dFV1Ld1vs09sRTfSfdCM2p1u9vKjwdcl2Qo4C3gP3azmkcCXgQxU25SDwOO95t6ydnzkLXRLTovb+9468L5r6T7oB/s/kQ8B1wLLqmpr4M+4f/835Aa6pbTxyq+vqkcO3B5RVUdsoK17+5vk4XTLdzcOPD/4Mxm7f6Ab4w8m2e/Bft4JLBno59a18M92W5AME826JHsleVOSXdv2bnQzkotalTOA45Ls0T7Y/jfwT1V195imtgS2AtYDd7dZymGzMIRH0IXbemBRkrfSzUxGnQmckGRxG+PrN9LWT4Hb2wztNVPoxynAm5P8ejqPawfOvwH8tJ148NAkWyR5YpKnbKCtI5I8sx38fwdwcVVNNEP4MrBnkt9LsijJ/6A7lvTFKfSdqloLnAv8dZKt05148dgkz55KO5obDBMNw2106/oXJ/kZXYisBN7Unj8V+DjwNeB64BeM84FcVbcBb6D78L4F+D26Yy8z7RzgX+lOJPhe69/gB+/bW/n1dB+WH99AW2+m6/dtwD8C/zTZTlTVZ4B30p0AcBvd8aJtq+oe4DfpThC4nu47H6cA454R13yKbrnwZuDX6Q7IT/S+P6Y7KeBNwI+BPwVeUFU3TbbvA15B90vB1XT78LPATpvQjoYsVZ4KLm3O2um8a6rqL4bdF81fzkwkSb0ZJpKk3lzmkiT15sxEktTbZvOlxSVLltTSpUuH3Q1JmlcuvfTSm6pq+43V22zCZOnSpaxYsWLY3ZCkeSXJhFdwGOQylySpN8NEktSbYSJJ6s0wkST1ZphIknozTCRJvRkmkqTeDBNJUm+GiSSpN8NEktSbYSJJ6s0wkST1ZphIknozTCRJvRkmkqTeDBNJUm+GiSSpN8NEktSbYSJJ6s0wkST1ZphIknozTCRJvRkmkqTeDBNJUm+GiSSpt1kNkySnJlmXZOVA2bZJzkuyqt0vHvOapyS5J8mLBsqWt/qrkiyfzTFIkh5otmcmpwGHjyk7Hji/qpYB57dtAJJsAbwLOGegbFvgROCpwAHAiWMDSJI0u2Y1TKrqa8DNY4qPBE5vj08HfnvgudcDZwHrBsqeB5xXVTdX1S3AeTwwoCRJs2guHDPZsarWArT7HQCS7AL8DvDhMfV3AW4Y2F7Tyh4gydFJViRZsX79+mnvuCSpMxfCZCLvB95SVfeMKc84dWu8Bqrq5KoaqaqR7bfffto7KEnqLBp2B4AfJdmpqtYm2Yn7lrRGgE8nAVgCHJHkbrqZyMEDr98V+I/Z664kaay5MDM5Gxg9I2s58AWAqtqjqpZW1VLgs8Brq+rzdAfjD0uyuB14P4yBA/SSpNk3qzOTJGfQzSqWJFlDd1bWScCZSY4Cvg+8eENtVNXNSd4BXNKK/rKqxh7UlyTNolSNe7hhwRkZGakVK1YMuxuSNK8kubSqRjZWby4sc0mS5jnDRJLUm2EiSerNMJEk9WaYSJJ6M0wkSb0ZJpKk3gwTSVJvhokkqTfDRJLUm2EiSerNMJEk9WaYSJJ6M0wkSb0ZJpKk3gwTSVJvhokkqTfDRJLUm2EiSerNMJEk9WaYSJJ6M0wkSb0ZJpKk3gwTSVJvhokkqTfDRJLUm2EiSerNMJEk9WaYSJJ6M0wkSb3NapgkOTXJuiQrB8q2TXJeklXtfnErf1mSK9rtP5PsO/Caw5N8K8nqJMfP5hgkSQ802zOT04DDx5QdD5xfVcuA89s2wPXAs6vqScA7gJMBkmwBfBB4PrAP8NIk+8x81yVJE5nVMKmqrwE3jyk+Eji9PT4d+O1W9z+r6pZWfhGwa3t8ALC6qr5TVb8EPt3akCQNyVw4ZrJjVa0FaPc7jFPnKOBf2+NdgBsGnlvTyiRJQ7Jo2B3YmCTPoQuTZ44WjVOtJnjt0cDRALvvvvuM9E+SNDdmJj9KshNAu183+kSSJwGnAEdW1Y9b8Rpgt4HX7wrcOF7DVXVyVY1U1cj2228/I52XJM2NMDkbWN4eLwe+AJBkd+BzwMur6rqB+pcAy5LskWRL4CWtDUnSkMzqMleSM4CDgSVJ1gAnAicBZyY5Cvg+8OJW/a3AdsDfJwG4u80y7k7yOuAcYAvg1Kq6ajbHIUm6v1SNe7hhwRkZGakVK1YMuxuSNK8kubSqRjZWby4sc0mS5jnDRJLUm2EiSerNMJEk9WaYSJJ6M0wkSb0ZJpKk3gwTSVJvhokkqTfDRJLUm2EiSerNMJEk9WaYSJJ6M0wkSb0ZJpKk3gwTSVJvhokkqTfDRJLU2yaFSZJfS7LFdHdGkjQ/TSpMkjwoye8l+VKSdcC1wNokVyX5v0mWzWw3JUlz2WRnJl8FHgucADyqqnarqh2Ag4CLgJOS/P4M9VGSNMctmmS9Q6vqrrGFVXUzcBZwVpIHT2vPJEnzxqRmJuMFyabUkSQtTBsNkyS/keQfk+zXto+e+W5JkuaTySxzvRZ4FfAXSbYF9pvZLkmS5pvJLHOtr6qfVNWbgcOAp8xwnyRJ88xkwuRLow+q6njgYzPXHUnSfLTRMKmqL4wp+vAM9UWSNE9N9tRgAJKcArwwyc+AG4ErgCuq6m9nonOSpPlhSmFC9yXFHavqriS7APsCT5r+bkmS5pOphslFwGJgXVX9APgB8OVp75UkaV6Z6oUeTwYuSPLmJAcl2WYqL05yapJ1SVYOlG2b5Lwkq9r94laeJB9IsjrJFUn2H3jN8lZ/VZLlUxyDJGmaTTVMPgGcSTejeS3wn0m+PYXXnwYcPqbseOD8qloGnN+2AZ4PLGu3o4EPQRc+wInAU4EDgBNHA0iSNBxTXeZaU1UnDhYk2WqyL66qryVZOqb4SODg9vh04D+At7Tyj1VVARcleWSSnVrd89p1wUhyHl1AnTHFsUzK2//lKq6+8acz0bQkzYp9dt6aE3/zCTP6HlOdmVyW5I2DBVV1Z88+7FhVa1tba4EdWvkuwA0D9da0sonKHyDJ0UlWJFmxfv36nt2UJE1kqjOTHYFDk7wF+G/gcuCyqvrMtPcMMk5ZbaD8gYVVJ9Md52FkZGTcOhsz02kuSQvBlGYmVfW7VbU3sAfwVuA6uuMWffyoLV/R7te18jXAbgP1dqX7bstE5ZKkIZnsX1p8WpJ7ZwRVdWdV/XdVnV5Vf9KzD2cDo2dkLQe+MFD+inZW14HArW0Z7BzgsCSL24H3w1qZJGlIJrvMtRz4YJLrgK8AX6mqH071zZKcQXcAfUmSNXRnZZ0EnJnkKOD7wItb9S8DRwCrgTvorlxMVd2c5B3AJa3eX44ejJckDUe6k6UmWTnZi+6U3ecB29D9Od+vAF+vqntmpIfTZGRkpFasWDHsbkjSvJLk0qoa2Vi9yS5zPQygqq6tqvdV1eHAIcCFdDOJi/t0VpI0v012meu6JF8APlxVVwJU1c/plqK8nIokbeYmezbX44HLgI8kuTDJy6fyZUVJ0sI2qTCpqp9V1T9W1QHA64CnA9ckeU+SPWe0h5KkOW9Sy1xJHgdsDTyi3V8IfBt4NXAcsMVMdVCSNPdN+pgJ3eXm/xm4BbgduA34y3YvSdqMTTZM9gf+CHgO8Gm6CzD+aMZ6JUmaVyZ7zOSyqnoNcCDd5U4+n+TMJIfMaO8kSfPCVC/0+Cu6y518le57Jn+fhKraa9p7JkmaNyZ7AP6W9vBnwE/b7TbgKuDWmemaJGm+mOzMZLuq+tWGKiRJTeXaLJKkBWOyX1r89ySvT7L7YGGSLZMckuR07rvyryRpMzPZmcnhwB8AZyTZA/gJ8FC6MDoXeF9VXTYzXZQkzXWTCpOq+gXw93QH3B8MLAF+XlU/mcnOSZLmh6mezUVV3QWsnYG+SJLmqSn92V5JksZjmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1NucCZMkb0yyMslVSY5tZfsluSjJZUlWJDmglSfJB5KsTnJFkv2H23tJ2rzNiTBJ8kTg1cABwL7AC5IsA94NvL2q9gPe2rYBng8sa7ejgQ/NeqclSfeaE2EC7A1cVFV3VNXdwAXA7wAFbN3qbAPc2B4fCXysOhcBj0yy02x3WpLUmfKf7Z0hK4F3JtkO+DlwBLACOBY4J8l76ILv6a3+LsANA69f08r8c8KSNARzYmZSVdcA7wLOA74CXA7cDbwGOK6qdgOOAz7SXpLxmhlbkOTodqxlxfr162ek75KkORImAFX1karav6qeBdwMrAKWA59rVT5Dd0wFupnIbgMv35X7lsAG2zy5qkaqamT77befuc5L0mZuzoRJkh3a/e7AC4Ez6ALi2a3KIXQBA3A28Ip2VteBwK1V5RKXJA3JXDlmAnBWO2ZyF3BMVd2S5NXA3yRZBPyC7swtgC/THVdZDdwBvGoYHZYkdeZMmFTVQeOUXQj8+jjlBRwzG/2SJG3cnFnmkiTNX4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9zZkwSfLGJCuTXJXk2IHy1yf5Vit/90D5CUlWt+eeN5xeS5IAFg27AwBJngi8GjgA+CXwlSRfAnYFjgSeVFV3Jtmh1d8HeAnwBGBn4N+S7FlV9wxlAJK0mZsrM5O9gYuq6o6quhu4APgd4DXASVV1J0BVrWv1jwQ+XVV3VtX1wGq6IJIkDcFcCZOVwLOSbJfkYcARwG7AnsBBSS5OckGSp7T6uwA3DLx+TSu7nyRHJ1mRZMX69etneAiStPmaE8tcVXVNkncB5wG3A5cDd9P1bzFwIPAU4MwkjwEyXjPjtHsycDLAyMjIA56XJE2PuTIzoao+UlX7V9WzgJuBVXQzjs9V5xvAr4AlrXy3gZfvCtw4232WJHXmTJgMHFzfHXghcAbweeCQVr4nsCVwE3A28JIkWyXZA1gGfGMY/ZYkzZFlruasJNsBdwHHVNUtSU4FTk2yku4sr+VVVcBVSc4ErqZbDjvGM7kkaXjmTJhU1UHjlP0S+P0J6r8TeOdM90uStHFzZplLkjR/GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSejNMJEm9GSaSpN4ME0lSb4aJJKk3w0SS1JthIknqzTCRJPVmmEiSektVDbsPsyLJeuB7m/jyJcBN09id+cAxbx4c8+ahz5gfXVXbb6zSZhMmfSRZUVUjw+7HbHLMmwfHvHmYjTG7zCVJ6s0wkST1ZphMzsnD7sAQOObNg2PePMz4mD1mIknqzZmJJKk3w0SS1JthshFJDk/yrSSrkxw/7P5MlyS7JflqkmuSXJXkja182yTnJVnV7he38iT5QPs5XJFk/+GOYNMk2SLJN5N8sW3vkeTiNt5/SrJlK9+qba9uzy8dZr83VZJHJvlskmvbvn7aZrCPj2v/plcmOSPJQxbafk5yapJ1SVYOlE15vyZZ3uqvSrK8T58Mkw1IsgXwQeD5wD7AS5PsM9xeTZu7gTdV1d7AgcAxbWzHA+dX1TLg/LYN3c9gWbsdDXxo9rs8Ld4IXDOw/S7gfW28twBHtfKjgFuq6nHA+1q9+ehvgK9U1V7AvnRjX7D7OMkuwBuAkap6IrAF8BIW3n4+DTh8TNmU9muSbYETgacCBwAnjgbQJqkqbxPcgKcB5wxsnwCcMOx+zdBYvwD8BvAtYKdWthPwrfb4H4CXDtS/t958uQG7tv9khwBfBEL3reBFY/c3cA7wtPZ4UauXYY9hiuPdGrh+bL8X+D7eBbgB2Lbtty8Cz1uI+xlYCqzc1P0KvBT4h4Hy+9Wb6s2ZyYaN/sMctaaVLShtav9k4GJgx6paC9Dud2jVFsLP4v3AnwK/atvbAT+pqrvb9uCY7h1ve/7WVn8+eQywHvhoW9o7JcmvsYD3cVX9AHgP8H1gLd1+u5SFvZ9HTXW/Tuv+Nkw2LOOULahzqZM8HDgLOLaqfrqhquOUzZufRZIXAOuq6tLB4nGq1iSemy8WAfsDH6qqJwM/476lj/HM+zG3ZZojgT2AnYFfo1vmGWsh7eeNmWiM0zp2w2TD1gC7DWzvCtw4pL5MuyQPpguST1bV51rxj5Ls1J7fCVjXyuf7z+IZwG8l+S7wabqlrvcDj0yyqNUZHNO9423PbwPcPJsdngZrgDVVdXHb/ixduCzUfQxwKHB9Va2vqruAzwFPZ2Hv51FT3a/Tur8Nkw27BFjWzgTZku5A3tlD7tO0SBLgI8A1VfXegafOBkbP6lhOdyxltPwV7cyQA4FbR6fU80FVnVBVu1bVUrr9+O9V9TLgq8CLWrWx4x39Obyo1Z9Xv7FW1Q+BG5I8vhU9F7iaBbqPm+8DByZ5WPs3PjrmBbufB0x1v54DHJZkcZvRHdbKNs2wDyLN9RtwBHAd8G3gz4fdn2kc1zPpprRXAJe12xF068XnA6va/batfujObPs2cCXd2TJDH8cmjv1g4Ivt8WOAbwCrgc8AW7Xyh7Tt1e35xwy735s41v2AFW0/fx5YvND3MfB24FpgJfBxYKuFtp+BM+iOCd1FN8M4alP2K/AHbeyrgVf16ZOXU5Ek9eYylySpN8NEktSbYSJJ6s0wkST1ZphIknpbtPEq0uYpyeiplgCPAu6huzwJwB1V9fQZeM8nA8dU1R9OU3uvA35WVR+djvakiXhqsDQJSd4G3F5V75nh9/kM8FdVdfk0tfcw4OvVXU5FmjEuc0mbIMnt7f7gJBckOTPJdUlOSvKyJN9IcmWSx7Z62yc5K8kl7faMcdp8BPCk0SBJ8uwkl7XbN9vzJPmT1sYVSd4+8PpXtLLLk3wcoKruAL6b5ICZ/6loc+Yyl9TfvsDedNd0+g5wSlUdkO4Pjr0eOJbu74q8r6ouTLI73WUr9h7Tzgjdt7ZHvZluyevr7YKcv0hyGN3fpTiA7pvNZyd5FvBj4M+BZ1TVTe1vVYxaARxE9w1vaUYYJlJ/l1S7hlWSbwPntvIrgee0x4cC+3SXiwJg6ySPqKrbBtrZifuOyQB8HXhvkk8Cn6uqNS1MDgO+2eo8nC5c9gU+W1U3AVTV4MUK1wF79R+mNDHDROrvzoHHvxrY/hX3/R97EN0fYfr5Btr5Od21ogCoqpOSfInummkXJTmUbjbyf6rqHwZfmOQNTHz58Ie0tqUZ4zETaXacC7xudCPJfuPUuQZ43ECdx1bVlVX1Lrqlqr3olsf+oC17kWSXJDvQnXX2u+0MNMYsc+3J/ZfPpGlnmEiz4w3ASDtAfjXwx2MrVNW1wDajB9qBY5OsTHI53cziX6vqXOBTwH8luZLub5Q8oqquAt4JXNDqD/5ZgWcA/zZjI5Pw1GBpTklyHHBbVZ0yTe09GfifVfXy6WhPmogzE2lu+RD3PwbT1xLgf01je9K4nJlIknpzZiJJ6s0wkST1ZphIknozTCRJvRkmkqTe/j9a/BgWe8M1WQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grafos.plotear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f06e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
